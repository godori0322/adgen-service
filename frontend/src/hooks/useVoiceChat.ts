// src/hooks/useVoiceChat.ts
import { useEffect, useRef, useState } from "react";
import {
  generateAudioRaw,
  generateDialogueRequest,
  generateSyntheSizeDiffusionRequest,
  uploadImage,
} from "../api/generate";
import type { ImageMode } from "../components/voice/ImageModeSelectorBubble";
import { IMAGE_GUIDE_MESSAGE } from "../constants/chat";
import { useAuth } from "../context/AuthContext";
import { useChat } from "../context/ChatContext";
import { formatChatResponse } from "../utils/chatFormatter";
import { blobToBase64, blobToFile, fileToBase64 } from "../utils/files";
import { useDotsAnimation } from "./useDotsAnimation";
import { useWhisper } from "./useWhisper";

export function useVoiceChat() {
  const { isLogin } = useAuth();
  const [isWorking, setIsWorking] = useState(false);
  const { messages, addMessage, updateTempMessage } = useChat();
  const { startDots, stopDots } = useDotsAnimation();
  const [needImage, setNeedImage] = useState(false);
  const [uploadedImageFile, setUploadedImageFile] = useState<File | null>(null);
  const [imageMode, setImageMode] = useState<ImageMode | null>(null);
  const [isCaptionEditing, setIsCaptionEditing] = useState(false);

  const [needBgmChoice, setNeedBgmChoice] = useState(false);
  const pendingQuestionRef = useRef<string | null>(null);
  const sessionKeyRef = useRef<string | null>(null);
  const userSelectBgmRef = useRef<"video" | "image" | "separate" | null>(null);
  const isResetRef = useRef(false);

  const imagePromptRef = useRef<string | null>(null);
  const bgmPromptRef = useRef<string | null>(null);
  const captionTextRef = useRef<string | null>(null);

  const updateSessionKey = (key: string) => {
    sessionKeyRef.current = key;
  };
  useEffect(() => {
    resetChatFlow();
  }, []);
  // ì´ë¯¸ì§€ or ë™ì˜ìƒ ìƒì„±
  const processImageOrVideo = async () => {
    const mode = userSelectBgmRef.current;
    if (!uploadedImageFile || !imageMode || !imagePromptRef.current || !mode) return;

    const msgId = Date.now();
    addMessage({
      role: "assistant",
      tempId: msgId,
      content: mode === "video" ? "ðŸŽ¬ ë™ì˜ìƒ ìƒì„± ì¤‘..." : "ðŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...",
    });

    try {
      const blob = await generateSyntheSizeDiffusionRequest(
        imagePromptRef.current,
        uploadedImageFile,
        imageMode,
        mode === "video" ? bgmPromptRef.current! : undefined
      );

      if (!blob) throw new Error("Blob empty");

      const base64 = await blobToBase64(blob, mode === "video" ? "video" : "image");

      updateTempMessage(msgId, {
        content: mode === "video" ? "ðŸŽ¬ ë™ì˜ìƒ ìƒì„± ì™„ë£Œ!" : "ðŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!",
        ...(mode === "video" ? { video: base64 } : { img: base64 }),
      });

      if (mode === "image") {
        const tempId = Date.now();
        const imgObj = new Image();
        imgObj.src = base64;
        const resultFile = blobToFile(blob, "generated_image.png");
        imgObj.onload = () => {
          if (captionTextRef.current) {
            addMessage({
              tempId,
              role: "assistant",
              content: "ðŸ“ ìƒì„±ëœ ê´‘ê³  ë¬¸êµ¬ë¥¼ ì´ë¯¸ì§€ì— ë„£ì–´ë³¼ê¹Œìš”?",
              captionSelect: true,
              textData: {
                caption: captionTextRef.current,
                imgWidth: imgObj.width,
                imgHeight: imgObj.height,
                file: resultFile,
              },
            });
            setIsCaptionEditing(true);
          }
        };
      }

      // ë”°ë¡œì¼ ê²½ìš° â†’ ì´ë¯¸ì§€ ì™„ë£Œ í›„ ìŒì•… ìƒì„±
      if (mode === "separate") {
        await processAudio();
      }
    } catch (err) {
      updateTempMessage(msgId, {
        content:
          mode === "video"
            ? "ë™ì˜ìƒ ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            : "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        fail: true,
      });
    } finally {
      setUploadedImageFile(null); // ë‹¤ìŒ ì—…ë¡œë“œ ëŒ€ê¸°
    }
  };

  // ìŒì› ìƒì„±
  const processAudio = async () => {
    if (!bgmPromptRef.current) return;

    const msgId = Date.now();
    addMessage({
      role: "assistant",
      tempId: msgId,
      content: "ðŸŽµ ìŒì•… ìƒì„± ì¤‘...",
    });

    try {
      const audioBlob = await generateAudioRaw(bgmPromptRef.current);
      const base64Audio = await blobToBase64(audioBlob, "audio");

      updateTempMessage(msgId, {
        content: "ðŸŽ¶ ìŒì•… ìƒì„± ì™„ë£Œ!",
        audio: base64Audio,
      });
    } catch {
      updateTempMessage(msgId, {
        content: "ìŒì•… ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        fail: true,
      });
    }
  };

  const retryProcess = async () => {
    const mode = userSelectBgmRef.current;

    if (!mode) {
      const last = messages[messages.length - 1];
      if (last?.tempId) {
        updateTempMessage(last.tempId, {
          content: "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ëŒ€í™”ë¥¼ ì‹œìž‘í•´ì£¼ì„¸ìš” ðŸ˜¥",
          img: undefined,
          video: undefined,
          audio: undefined,
          modeSelect: false,
          bgmSelect: false,
          fail: false,
        });
      }

      resetChatFlow();
      return;
    }

    if (mode === "separate") {
      await processAudio();
    } else {
      await processImageOrVideo();
    }
  };

  const onAudioSend = async (audioBlob: Blob) => {
    if (isResetRef.current) {
      isResetRef.current = false;
    }
    setIsWorking(true);
    if (audioBlob.size < 10000) {
      addMessage({
        role: "assistant",
        content: "ðŸŽ¤ ìŒì„±ì´ ë„ˆë¬´ ì§§ì•„ìš”! ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš” ðŸ˜…",
      });
      setIsWorking(false);
      return;
    }

    try {
      // 1) ìœ ì € ë²„ë¸” ë¡œë”©
      const userTempId = Date.now();
      addMessage({ role: "user", content: ".", tempId: userTempId });
      startDots(userTempId);

      // Whisper ë³€í™˜
      const userText = await useWhisper(audioBlob);
      stopDots(userTempId); // âœ… í•´ë‹¹ ë²„ë¸” ë¡œë”©ë§Œ ì¢…ë£Œ

      if (!userText || userText.trim() === "") {
        updateTempMessage(userTempId, {
          content: "ðŸŽ¤ ìŒì„±ì´ ìž˜ ì¸ì‹ë˜ì§€ ì•Šì•˜ì–´ìš”! ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì„¸ìš” ðŸ˜…",
        });
        setIsWorking(false);
        return;
      }
      updateTempMessage(userTempId, { content: userText });

      // 2) ì–´ì‹œìŠ¤í„´íŠ¸ ë²„ë¸” ë¡œë”©
      const assistantTempId = Date.now() + 1;
      addMessage({ role: "assistant", content: ".", tempId: assistantTempId });
      startDots(assistantTempId);

      // Dialogue API
      const adRes = await generateDialogueRequest(userText, isLogin);
      stopDots(assistantTempId); // âœ… ì´ ë²„ë¸” ë¡œë”© ì¢…ë£Œ

      pendingQuestionRef.current = adRes.next_question;
      if (sessionKeyRef.current !== adRes.session_key) updateSessionKey(adRes.session_key);

      // ë¦¬í„´ íƒ€ìž… ì„ íƒ
      if (!userSelectBgmRef.current && adRes.type === "ad" && !isResetRef.current) {
        setNeedBgmChoice(true);
        updateTempMessage(assistantTempId, {
          content: "ðŸŽ¬ ì–´ë–¤ ë°©ì‹ì˜ ê´‘ê³ ë¥¼ ì›í•˜ì‹œë‚˜ìš”?",
          bgmSelect: true,
        });
        return;
      }

      // ì´ë¯¸ì§€ ìš”ì²­
      if (!uploadedImageFile && adRes.type === "ad" && !isResetRef.current) {
        setNeedImage(true);
        updateTempMessage(assistantTempId, {
          content: IMAGE_GUIDE_MESSAGE,
        });
        return;
      }

      // ë‹¤ìŒ ì§ˆë¬¸ í‘œì‹œ
      if (pendingQuestionRef.current !== null) {
        const nextQ = pendingQuestionRef.current.trim();
        pendingQuestionRef.current = null;

        if (nextQ.length > 0) {
          updateTempMessage(assistantTempId, {
            content: nextQ,
          });
        } else {
          updateTempMessage(assistantTempId, {
            content: "ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ðŸ˜Š\nì›í•˜ì‹œë©´ ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ì‹œìž‘í•´ë³¼ê¹Œìš”?",
          });
          resetChatFlow();
        }

        return;
      }

      // ìµœì¢… ë¬¸êµ¬ ì²˜ë¦¬
      const content = adRes.final_content
        ? formatChatResponse(adRes.final_content)
        : adRes.last_ment ?? "";
      updateTempMessage(assistantTempId, { content });

      if (adRes.final_content?.caption) {
        captionTextRef.current = adRes.final_content.caption;
      }

      // Diffusion ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„
      imagePromptRef.current = adRes.final_content?.image_prompt || null;
      bgmPromptRef.current = adRes.final_content?.bgm_prompt || null;

      if (imagePromptRef.current && userSelectBgmRef.current) {
        await processImageOrVideo();
      }
    } catch (err) {
      addMessage({
        role: "assistant",
        content: "âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!",
      });
      stopDots(); // âœ… í˜¹ì‹œ ë‚¨ì•„ìžˆì„ì§€ ëª¨ë¥´ëŠ” ë¡œë”© ì „ë¶€ ì •ë¦¬
    } finally {
      setIsWorking(false);
    }
  };

  const onImageUpload = async (file: File) => {
    const key = sessionKeyRef.current;
    if (!key) return;

    const base64Img = await fileToBase64(file);

    setUploadedImageFile(file);
    setNeedImage(false);

    try {
      await uploadImage(key, file);
    } catch (err) {
      console.error("ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨:", err);
    }

    addMessage({ role: "user", content: "", img: base64Img });

    addMessage({
      role: "assistant",
      content: "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í• ê¹Œìš”?",
      modeSelect: true,
    });
  };

  const onSelectMode = (mode: ImageMode) => {
    setImageMode(mode);

    addMessage({
      role: "user",
      content: `ðŸ‘‰ ${mode} ëª¨ë“œ ì„ íƒ!`,
    });
    if (pendingQuestionRef.current) {
      addMessage({
        role: "assistant",
        content: pendingQuestionRef.current,
      });
      pendingQuestionRef.current = null;
    }
  };

  const onSelectBgmOption = async (option: "video" | "image" | "separate") => {
    if (isResetRef.current) return;
    userSelectBgmRef.current = option;
    setNeedBgmChoice(false);

    addMessage({
      role: "user",
      content:
        option === "video"
          ? "ðŸŽ¬ ë™ì˜ìƒ(ë¦´ìŠ¤)ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”!"
          : option === "image"
          ? "ðŸ“¸ ì´ë¯¸ì§€ë§Œ ìƒì„±í• ê²Œìš”!"
          : "ðŸŽ¨ ì´ë¯¸ì§€ + ðŸŽµ ìŒì•…ì„ ë”°ë¡œ ìƒì„±í• ê²Œìš”!",
    });

    setNeedImage(true);
  };

  const onInsertCaption = async (choice: boolean, tempId?: number) => {
    setIsCaptionEditing(false);
    setNeedImage(false);

    if (!choice) {
      if (tempId) {
        updateTempMessage(tempId, {
          role: "assistant",
          content: "ë¬¸êµ¬ ì‚½ìž… ì—†ì´ ì™„ë£Œë˜ì—ˆì–´ìš” ðŸ˜Š",
        });
      }
    } else {
      addMessage({
        role: "assistant",
        content: "ë¬¸êµ¬ ì‚½ìž… ì—†ì´ ì™„ë£Œë˜ì—ˆì–´ìš” ðŸ˜Š",
      });
    }

    // ì¢…ë£Œ ì•ˆë‚´ ë©˜íŠ¸
    addMessage({
      role: "assistant",
      content: "ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ðŸ˜Š\nì›í•˜ì‹œë©´ ìŒì„±ìœ¼ë¡œ ìƒˆë¡œìš´ ê´‘ê³ ë¥¼ ì‹œìž‘í•´ì£¼ì„¸ìš”!",
    });

    resetChatFlow();
  };
  const lastMsg = messages[messages.length - 1];

  const isUiBlocking =
    isWorking ||
    needImage ||
    isCaptionEditing ||
    (lastMsg?.modeSelect && userSelectBgmRef.current == null) ||
    (lastMsg?.bgmSelect && imageMode == null);

  const resetChatFlow = () => {
    isResetRef.current = true;

    setNeedImage(false);
    setNeedBgmChoice(false);
    setUploadedImageFile(null);
    setImageMode(null);
    setIsWorking(false);

    sessionKeyRef.current = null;
    pendingQuestionRef.current = null;
    userSelectBgmRef.current = null;
    imagePromptRef.current = null;
    bgmPromptRef.current = null;
    captionTextRef.current = null;
  };
  return {
    messages,
    needImage,
    needBgmChoice,
    isWorking,
    onAudioSend,
    onImageUpload,
    onSelectMode,
    onSelectBgmOption,
    retryProcess,
    resetChatFlow,
    onInsertCaption,
    isUiBlocking,
  };
}
