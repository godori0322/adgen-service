import { useRef, useState } from "react";
import {
  generateAudioRaw,
  generateDialogueRequest,
  generateSyntheSizeDiffusionRequest,
  uploadImage,
} from "../api/generate";
import type { ImageMode } from "../components/voice/ImageModeSelectorBubble";
import { IMAGE_GUIDE_MESSAGE } from "../constants/chat";
import { useAuth } from "../context/AuthContext";
import { useChat } from "../context/ChatContext";
import { formatChatResponse } from "../utils/chatFormatter";
import { useDotsAnimation } from "./useDotsAnimation";
import { useWhisper } from "./useWhisper";

export interface ChatMessage {
  role: "user" | "assistant";
  content?: string;
  img?: string;
  video?: string;
  audio?: string;
  tempId?: number;
  modeSelect?: boolean;
  bgmSelect?: boolean;
  retryType?: "image" | "video" | "audio";
}

export function useVoiceChat() {
  const { isLogin } = useAuth();
  const [isWorking, setIsWorking] = useState(false);
  const { messages, addMessage, updateTempMessage } = useChat();
  const { startDots, stopDots } = useDotsAnimation();
  const [needImage, setNeedImage] = useState(false);
  const [uploadedImageFile, setUploadedImageFile] = useState<File | null>(null);
  const [imageMode, setImageMode] = useState<ImageMode | null>(null);
  const [needBgmChoice, setNeedBgmChoice] = useState(false);
  const pendingQuestionRef = useRef<string | null>(null);
  const sessionKeyRef = useRef<string | null>(null);
  const userSelectBgmRef = useRef<"video" | "image" | "separate" | null>(null);

  const imagePromptRef = useRef<string | null>(null);
  const bgmPromptRef = useRef<string | null>(null);

  const updateSessionKey = (key: string) => {
    sessionKeyRef.current = key;
  };

  const toBase64 = (blob: Blob, type: "image" | "video" | "audio") => {
    return new Promise<string>((resolve) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result as string);
      reader.readAsDataURL(
        new File([blob], `file.${type === "image" ? "png" : type === "video" ? "mp4" : "mp3"}`, {
          type: blob.type,
        })
      );
    });
  };
  // ì´ë¯¸ì§€ or ë™ì˜ìƒ ìƒì„±
  const processImageOrVideo = async (mode: "image" | "video" | "separate") => {
    if (!uploadedImageFile || !imageMode || !imagePromptRef.current) return;

    const msgId = Date.now();
    addMessage({
      role: "assistant",
      tempId: msgId,
      content: mode === "video" ? "ğŸ¬ ë™ì˜ìƒ ìƒì„± ì¤‘..." : "ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...",
    });

    try {
      const blob = await generateSyntheSizeDiffusionRequest(
        imagePromptRef.current,
        uploadedImageFile,
        imageMode,
        mode === "video" ? bgmPromptRef.current! : undefined
      );

      if (!blob) throw new Error("Blob empty");

      const base64 = await toBase64(blob, mode === "video" ? "video" : "image");

      updateTempMessage(msgId, {
        content: mode === "video" ? "ğŸ¬ ë™ì˜ìƒ ìƒì„± ì™„ë£Œ!" : "ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!",
        ...(mode === "video" ? { video: base64 } : { img: base64 }),
      });

      // ğŸ¨+ğŸµ ë”°ë¡œì¼ ê²½ìš° â†’ ì´ë¯¸ì§€ ì™„ë£Œ í›„ ìŒì•… ìƒì„±
      if (mode === "separate") {
        await processAudio();
      }
    } catch (err) {
      updateTempMessage(msgId, {
        content:
          mode === "video"
            ? "ë™ì˜ìƒ ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            : "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        retryType: mode === "video" ? "video" : "image",
      });
    } finally {
      setUploadedImageFile(null); // ë‹¤ìŒ ì—…ë¡œë“œ ëŒ€ê¸°
    }
  };
  // ìŒì› ìƒì„±
  const processAudio = async () => {
    if (!bgmPromptRef.current) return;

    const msgId = Date.now();
    addMessage({
      role: "assistant",
      tempId: msgId,
      content: "ğŸµ ìŒì•… ìƒì„± ì¤‘...",
    });

    try {
      const audioBlob = await generateAudioRaw(bgmPromptRef.current);
      const base64Audio = await toBase64(audioBlob, "audio");

      updateTempMessage(msgId, {
        content: "ğŸ¶ ìŒì•… ìƒì„± ì™„ë£Œ!",
        audio: base64Audio,
      });
    } catch {
      updateTempMessage(msgId, {
        content: "ìŒì•… ìƒì„± ì‹¤íŒ¨! ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        retryType: "audio",
      });
    }
  };

  const retryProcess = async (type: "image" | "video" | "audio") => {
    if (type === "image") {
      await processImageOrVideo("image");
    } else if (type === "video") {
      await processImageOrVideo("video");
    } else if (type === "audio") {
      await processAudio();
    }
  };

  const onAudioSend = async (audioBlob: Blob) => {
    setIsWorking(true);

    if (audioBlob.size < 10000) {
      addMessage({
        role: "assistant",
        content: "ğŸ¤ ìŒì„±ì´ ë„ˆë¬´ ì§§ì•„ìš”! ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš” ğŸ˜…",
      });
      setIsWorking(false);
      return;
    }

    try {
      const userTempId = Date.now();
      addMessage({ role: "user", content: ".", tempId: userTempId });
      startDots(userTempId);

      // Whisper ë³€í™˜
      const userText = await useWhisper(audioBlob);
      stopDots();
      if (!userText || userText.trim() === "") {
        updateTempMessage(userTempId, {
          content: "ğŸ¤ ìŒì„±ì´ ì˜ ì¸ì‹ë˜ì§€ ì•Šì•˜ì–´ìš”! ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì„¸ìš” ğŸ˜…",
        });
        setIsWorking(false);
        return;
      }
      updateTempMessage(userTempId, { content: userText });

      // Assistant ì„ì‹œ ë²„ë¸”
      const assistantTempId = Date.now() + 1;
      addMessage({ role: "assistant", content: ".", tempId: assistantTempId });
      startDots(assistantTempId);

      // Dialogue API
      const adRes = await generateDialogueRequest(userText, isLogin);
      stopDots();

      if (sessionKeyRef.current !== adRes.session_key) updateSessionKey(adRes.session_key);

      // ì´ë¯¸ì§€ ìš”ì²­ ë‹¨ê³„
      if (!adRes.is_complete) {
        if (adRes.type === "ad" && !uploadedImageFile) {
          pendingQuestionRef.current = adRes.next_question;
          setNeedImage(true);
          updateTempMessage(assistantTempId, {
            content: IMAGE_GUIDE_MESSAGE,
          });
          return;
        }

        updateTempMessage(assistantTempId, {
          content: adRes.next_question,
        });
        return;
      }

      // ìµœì¢… ë¬¸êµ¬ ì²˜ë¦¬
      const content = adRes.final_content
        ? formatChatResponse(adRes.final_content)
        : adRes.last_ment ?? "";
      updateTempMessage(assistantTempId, { content });

      // Diffusion ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„

      imagePromptRef.current = adRes.final_content?.image_prompt || null;
      bgmPromptRef.current = adRes.final_content?.bgm_prompt || null;

      if (bgmPromptRef.current!) {
        setNeedBgmChoice(true);
        addMessage({
          role: "assistant",
          content: `ğŸ–¼ï¸ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë°°ê²½ ìŒì•…ë„ ë§Œë“¤ì–´ë“œë¦´ê¹Œìš”?`,
          bgmSelect: true,
        });
        return;
      }
    } catch (err) {
      addMessage({
        role: "assistant",
        content: "âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!",
      });
      stopDots();
    } finally {
      setIsWorking(false);
    }
  };

  const fileToBase64 = (file: File): Promise<string> =>
    new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result as string);
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });

  const onImageUpload = async (file: File) => {
    const key = sessionKeyRef.current;
    if (!key) return;

    const base64Img = await fileToBase64(file);

    setUploadedImageFile(file);
    setNeedImage(false);

    await uploadImage(key, file);

    addMessage({ role: "user", content: "", img: base64Img });

    addMessage({
      role: "assistant",
      content: "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í• ê¹Œìš”?",
      modeSelect: true,
    });
  };

  const onSelectMode = (mode: ImageMode) => {
    setImageMode(mode);

    addMessage({
      role: "user",
      content: `ğŸ‘‰ ${mode} ëª¨ë“œ ì„ íƒ!`,
    });

    const lastMsg = messages[messages.length - 1];
    if (lastMsg?.modeSelect && lastMsg.tempId) {
      updateTempMessage(lastMsg.tempId, { modeSelect: false });
    }

    if (pendingQuestionRef.current) {
      addMessage({
        role: "assistant",
        content: pendingQuestionRef.current,
      });
      pendingQuestionRef.current = null;
    }
  };

  const onSelectBgmOption = async (option: "video" | "image" | "separate") => {
    userSelectBgmRef.current = option;
    setNeedBgmChoice(false);

    addMessage({
      role: "user",
      content:
        option === "video"
          ? "ğŸ¬ ë™ì˜ìƒìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”!"
          : option === "image"
          ? "ğŸ“¸ ì´ë¯¸ì§€ë§Œ ìƒì„±í• ê²Œìš”!"
          : "ğŸ¨ ì´ë¯¸ì§€ + ğŸµ ìŒì•…ì„ ë”°ë¡œ ìƒì„±í• ê²Œìš”!",
    });

    const lastMsg = messages[messages.length - 1];
    if (lastMsg?.bgmSelect && lastMsg.tempId) {
      updateTempMessage(lastMsg.tempId, { bgmSelect: false });
    }

    await processImageOrVideo(option);
  };

  return {
    messages,
    needImage,
    needBgmChoice,
    isWorking,
    onAudioSend,
    onImageUpload,
    onSelectMode,
    onSelectBgmOption,
    retryProcess,
  };
}
