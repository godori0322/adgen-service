# gpt_service.py
# generat_marketing_idae í•¨ìˆ˜ ìœ ì§€
# langchain ì‚¬ìš© _get_or_create_chain, generate_conversation_response í•¨ìˆ˜ ì¶”ê°€

import os
import json
import re  # ì •ê·œì‹ ì‚¬ìš© ëª©ì 
import asyncio
from typing import Optional, Dict
from datetime import datetime
from enum import Enum
from openai import AsyncOpenAI
from langchain_openai import ChatOpenAI
from langchain_classic.chains import ConversationChain
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from backend.app.core.schemas import DialogueGPTResponse_AD, DialogueGPTResponse_Profile, FinalContentSchema

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================== ëŒ€í™” ì˜ë„ ë¶„ë¥˜ ==================

class ConversationIntent(str, Enum):
    """ëŒ€í™” ì˜ë„ ë¶„ë¥˜"""
    PROFILE_BUILDING = "profile_building"  # ì²« ëŒ€í™”: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘ (ë¡œê·¸ì¸)
    GUEST_PROFILE = "guest_profile"  # ì²« ëŒ€í™”: ì¶•ì•½ í”„ë¡œí•„ ìˆ˜ì§‘ (ë¹„ë¡œê·¸ì¸)
    INFO_UPDATE = "info_update"  # ì •ë³´ ì—…ë°ì´íŠ¸
    AD_GENERATION = "ad_generation"  # ê´‘ê³  ìƒì„±
    ANALYSIS = "analysis"  # ë¶„ì„/ì¡°ì–¸


def classify_user_intent(user_input: str, has_complete_profile: bool) -> ConversationIntent:
    """
    ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        has_complete_profile: í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        
    Returns:
        ConversationIntent
    """
    
    # ì²« ëŒ€í™”ëŠ” ë¬´ì¡°ê±´ í”„ë¡œí•„ ìˆ˜ì§‘
    if not has_complete_profile:
        return ConversationIntent.PROFILE_BUILDING
    
    # ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­
    user_input_lower = user_input.lower()
    
    # ê´‘ê³  ìƒì„± ê´€ë ¨ í‚¤ì›Œë“œ
    ad_keywords = ['ê´‘ê³ ', 'ì´ë¯¸ì§€', 'í¬ìŠ¤í„°', 'í™ë³´', 'ë°°ë„ˆ', 'ë§Œë“¤ì–´', 'ìƒì„±', 'ë””ìì¸', 'ì•„ì´ë””ì–´']
    if any(keyword in user_input_lower for keyword in ad_keywords):
        return ConversationIntent.AD_GENERATION
    
    # ì •ë³´ ì—…ë°ì´íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ
    update_keywords = ['ìš”ì¦˜', 'ìš”ìƒˆ', 'ìµœê·¼', 'ì§€ê¸ˆ', 'ë°”ë€Œ', 'ë³€ê²½', 'ëŠ˜ì—ˆ', 'ì¤„ì—ˆ', 'ë§ì•„', 'ì ì–´', 'ë‹¬ë¼', 'ë‹¤ë¥´']
    if any(keyword in user_input_lower for keyword in update_keywords):
        return ConversationIntent.INFO_UPDATE
    
    # ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ
    analysis_keywords = ['ì™œ', 'ì´ìœ ', 'ë¶„ì„', 'ì–´ë–»ê²Œ', 'ì¶”ì²œ', 'ì¡°ì–¸', 'ë„ì›€']
    if any(keyword in user_input_lower for keyword in analysis_keywords):
        return ConversationIntent.ANALYSIS
    
    # ê¸°ë³¸ê°’: ê´‘ê³  ìƒì„±
    return ConversationIntent.AD_GENERATION

# langchain ë³€ìˆ˜ ì •ì˜
MAX_MEMORY_TURNS = 10
parser_ad = PydanticOutputParser(pydantic_object=DialogueGPTResponse_AD)
parser_profile = PydanticOutputParser(pydantic_object=DialogueGPTResponse_Profile)

# ì‚¬ìš©ìë³„ ëŒ€í™” ì„¸ì…˜ ì €ì¥ (user_id -> {chain, last_access})
CONVERSATION_MEMORIES: Dict[str, Dict] = {}

# ================== í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤ ==================

# 1ï¸âƒ£ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘ í”„ë¡¬í”„íŠ¸ (ì²« ëŒ€í™” ì „ìš©)
PROFILE_BUILDING_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ê¸°ë³¸ ì •ë³´ (ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´) ===
ì—…ì¢…: {business_type}
ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}
ì˜ì—…ì‹œê°„: {business_hours}

=== í˜„ì¬ ìˆ˜ì§‘ëœ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì´ë²ˆì´ ì²« ëŒ€í™”ì´ë¯€ë¡œ, íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ…ì„ ìœ„í•´ ë‹¤ìŒ í•µì‹¬ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì§‘í•˜ì„¸ìš”:

1. **íƒ€ê²Ÿ ê³ ê°** (ì—°ë ¹ëŒ€, ì„±ë³„, ì§ì—…, íŠ¹ì„±)
   - ì˜ˆ: "ì£¼ë¡œ ì–´ë–¤ ê³ ê°ì¸µì´ ë§ì´ ë°©ë¬¸í•˜ì‹œë‚˜ìš”?"
   
2. **ì°¨ë³„í™” í¬ì¸íŠ¸** (ê²½ìŸì—…ì²´ ëŒ€ë¹„ ê°•ì )
   - ì˜ˆ: "ì£¼ë³€ {business_type}ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ íŠ¹ë³„í•œ ê°•ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
   
3. **ë¸Œëœë“œ ì»¨ì…‰** (ì¶”êµ¬í•˜ëŠ” ì´ë¯¸ì§€, ë¶„ìœ„ê¸°)
   - ì˜ˆ: "ì–´ë–¤ ë¶„ìœ„ê¸°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì¶”êµ¬í•˜ì‹œë‚˜ìš”?"
   
4. **ë§ˆì¼€íŒ… ëª©í‘œ** (ì‹ ê·œ ê³ ê° ìœ ì¹˜? ì¬ë°©ë¬¸ ì¦ëŒ€? ë§¤ì¶œ ì¦ê°€?)
   - ì˜ˆ: "í˜„ì¬ ê°€ì¥ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?"

=== ì¤‘ìš” ê·œì¹™ ===
- í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì„¸ìš” (ì—¬ëŸ¬ ì§ˆë¬¸ ë™ì‹œ ê¸ˆì§€)
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™” í†¤ ìœ ì§€
- ì‚¬ìš©ìê°€ ë‹µë³€í•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œë‚˜ ì„ íƒì§€ ì œê³µ
- ìœ„ 4ê°€ì§€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ:
  * is_complete: true
  * last_ment: "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤" 
- ê¸°ë³¸ ì •ë³´(ì—…ì¢…, ìœ„ì¹˜, ë©”ë‰´ ë“±)ëŠ” ì ˆëŒ€ ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”
- ê°™ì€ ë‚´ìš©ì˜ ì§ˆë¬¸ì„ ì ˆëŒ€ 3ë²ˆ ì´ìƒ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 2ï¸âƒ£ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì¶•ì•½ í”„ë¡œí•„ ìˆ˜ì§‘ ë° ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸
GUEST_PROFILE_TEMPLATE = """
ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë§ˆì¼€íŒ… ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

=== ëŒ€í™” ëª©í‘œ ===
ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìë¥¼ ìœ„í•œ ë¹ ë¥¸ ê´‘ê³  ìƒì„± ì²´í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.
ë‹¤ìŒ 3ê°€ì§€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•œ í›„ ì¦‰ì‹œ ê´‘ê³ ë¥¼ ìƒì„±í•˜ì„¸ìš”:

1. **ì—…ì¢…ê³¼ ìœ„ì¹˜** (ì˜ˆ: ì„œìš¸ ê°•ë‚¨ ì¹´í˜, ë¶€ì‚° í•´ìš´ëŒ€ ìŒì‹ì )
2. **ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì œí’ˆ ì‚¬ì§„ì˜ ì„¤ëª…** (ì˜ˆ: ì•„ë©”ë¦¬ì¹´ë…¸, ë¼ë–¼, ë””ì €íŠ¸)
3. **íƒ€ê²Ÿ ê³ ê°** (ì˜ˆ: 20ëŒ€ ì§ì¥ì¸, ëŒ€í•™ìƒ, 30ëŒ€ ì—¬ì„±)

=== ì§„í–‰ ë‹¨ê³„ ===
**1~2ë²ˆì§¸ ì§ˆë¬¸**: 
- í•œ ë²ˆì— í•˜ë‚˜ì”© ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸
- is_complete: false
- next_questionì— ë‹¤ìŒ ì§ˆë¬¸ ì‘ì„±

**3ë²ˆì§¸ ì§ˆë¬¸ ì‘ë‹µ ë°›ì€ í›„**:
- ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì¦‰ì‹œ ê´‘ê³  ìƒì„±**
- is_complete: true
- final_contentì— ê´‘ê³  ìƒì„±:
  * idea: ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ (êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´)
  * caption: í™ë³´ ë¬¸êµ¬ (SNS ê²Œì‹œë¬¼ìš© ë§¤ë ¥ì ì¸ ë¬¸êµ¬)
  * hashtags: í•´ì‹œíƒœê·¸ ë¦¬ìŠ¤íŠ¸ (5~7ê°œ, ê´€ë ¨ì„± ë†’ì€ íƒœê·¸)
  * image_prompt: ì´ë¯¸ì§€ ìƒì„±ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ë¡œ ì‘ì„±, Stable Diffusionìš©)

=== ì¤‘ìš” ê·œì¹™ ===
- 3ê°œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ **ë°˜ë“œì‹œ ê´‘ê³ ë¥¼ ìƒì„±**í•˜ì„¸ìš”
- ì‚¬ìš©ì í™•ì¸ ì—†ì´ ë°”ë¡œ ìƒì„± (ë¹ ë¥¸ ì²´í—˜ ì œê³µ)
- image_promptëŠ” ì˜ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„± (ë¶„ìœ„ê¸°, ìƒ‰ê°, êµ¬ì„± í¬í•¨)
- ê°„ê²°í•˜ê³  ë¹ ë¥´ê²Œ ì§„í–‰

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 3ï¸âƒ£ ì •ë³´ ì—…ë°ì´íŠ¸ í”„ë¡¬í”„íŠ¸
INFO_UPDATE_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== í˜„ì¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.

=== ì¤‘ìš” ê·œì¹™ ===
- ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ ì‹œ:
  * is_complete: true
  * last_ment: "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤" 

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 3ï¸âƒ£ ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸ (2ë‹¨ê³„: ì „ëµ í˜‘ì˜ â†’ ìµœì¢… ìƒì„±)
AD_GENERATION_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê´‘ê³ ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ **ì „ëµ í˜‘ì˜ í”„ë¡œì„¸ìŠ¤**ë¥¼ ë”°ë¥´ì„¸ìš”:

**ğŸ“‹ ë‹¨ê³„ 1: ê´‘ê³  ì „ëµ ì œì•ˆ**
ì‚¬ìš©ìê°€ ê´‘ê³ ë¥¼ ìš”ì²­í•˜ë©´, ì¦‰ì‹œ ìƒì„±í•˜ì§€ ë§ê³  ë¨¼ì € êµ¬ì²´ì ì¸ ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”:

1. **ë©”ì¸ ë©”ì‹œì§€**: í•µì‹¬ ë¬¸êµ¬ (ì˜ˆ: "ë”°ëœ»í•œ í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ê±´ê°•í•œ ë¹µê³¼ í•¨ê»˜")
2. **íƒ€ê²Ÿ ê³ ê°**: ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ? (ê¸°ì¡´ ì „ëµ ì •ë³´ í™œìš©)
3. **ë¹„ì£¼ì–¼ ì»¨ì…‰**: ì–´ë–¤ ëŠë‚Œ? (ì˜ˆ: ì•„ëŠ‘í•œ, íŠ¸ë Œë””í•œ, ê³ ê¸‰ìŠ¤ëŸ¬ìš´)
4. **ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼**: êµ¬ì²´ì ì¸ ë¹„ì£¼ì–¼ ë°©í–¥
5. **ì£¼ìš” ìš”ì†Œ**: í¬í•¨í•  ë‚´ìš© (ì œí’ˆ, ì´ë²¤íŠ¸, í• ì¸ ë“±)

ì „ëµ ì œì•ˆ í›„ ë°˜ë“œì‹œ:
- "ì´ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í• ê¹Œìš”?"
- "ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
- is_complete: falseë¡œ ì„¤ì •

**ğŸ”„ ë‹¨ê³„ 2: í”¼ë“œë°± ë°˜ì˜**
ì‚¬ìš©ìê°€ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´:
- í”¼ë“œë°±ì„ ë°˜ì˜í•œ **ìˆ˜ì •ëœ ì „ëµ**ì„ ë‹¤ì‹œ ì œì‹œ
- "ì´ë ‡ê²Œ ìˆ˜ì •í–ˆëŠ”ë°, ê´œì°®ìœ¼ì‹ ê°€ìš”?"
- ì—¬ì „íˆ is_complete: false

**âœ… ë‹¨ê³„ 3: ìµœì¢… ìƒì„±**
ì‚¬ìš©ìê°€ **ëª…í™•í•˜ê²Œ ë™ì˜**í•  ë•Œë§Œ ìµœì¢… ê´‘ê³ ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ë™ì˜ í‘œí˜„ ì˜ˆì‹œ:**
- "ì¢‹ì•„ìš”", "ê´œì°®ì•„ìš”", "ì˜¤ì¼€ì´", "ê·¸ë ‡ê²Œ í•´ì£¼ì„¸ìš”"
- "ë§Œë“¤ì–´ì£¼ì„¸ìš”", "ìƒì„±í•´ì£¼ì„¸ìš”", "ì§„í–‰í•´ì£¼ì„¸ìš”"
- "ë„¤", "ì‘", "ì˜ˆ", "ê·¸ë˜"

ë™ì˜ í™•ì¸ í›„:
- is_complete: true
- final_contentì— ìµœì¢… ê´‘ê³  ìƒì„± (idea, caption, hashtags, image_prompt)

=== ì¤‘ìš” ê·œì¹™ ===
1. **ì ˆëŒ€ ë°”ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”**: ì‚¬ìš©ì ë™ì˜ ì—†ì´ is_complete=true ê¸ˆì§€
2. **ì „ëµë§Œ ì œì•ˆ**: ë™ì˜ ì „ê¹Œì§€ëŠ” í•­ìƒ next_questionì— ì „ëµ ì œì•ˆ
3. **ëª…í™•í•œ ë™ì˜ ëŒ€ê¸°**: ì• ë§¤í•œ ë°˜ì‘ì—ëŠ” ë‹¤ì‹œ í™•ì¸
4. **ë¬´í•œ ìˆ˜ì • ê°€ëŠ¥**: ì‚¬ìš©ìê°€ ë§Œì¡±í•  ë•Œê¹Œì§€ ì „ëµ ì¡°ì •
5. **ê¸°ì¡´ ì •ë³´ í™œìš©**: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì ê·¹ ë°˜ì˜

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 4ï¸âƒ£ ë¶„ì„/ì¡°ì–¸ í”„ë¡¬í”„íŠ¸ (í‹€ë§Œ)
ANALYSIS_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
(ì´ í”„ë¡¬í”„íŠ¸ëŠ” í–¥í›„ êµ¬í˜„ ì˜ˆì •)

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""


def _safe_json_from_text(text: str) -> dict:
    """
    ëª¨ë¸ì´ ```json ... ``` ê°™ì€ ì½”ë“œë¸”ë¡ì„ ì„ì–´ ë³´ë‚´ê±°ë‚˜
    ìì—°ì–´ê°€ í•¨ê»˜ í¬í•¨ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•œ ì•ˆì „ íŒŒì„œ ì—­í• 
    """
    # 1) ì½”ë“œíœìŠ¤ ì œê±° ì‹œë„ ì—­í• 
    cleaned = text.replace("```json", "").replace("```", "").strip()

    # 2) ì •ê·œì‹ìœ¼ë¡œ ê°€ì¥ ë°”ê¹¥ { ... } ê°ì²´ë§Œ ì¶”ì¶œ ì‹œë„ ì—­í• 
    #    - ì¤‘ê°„ì— ì„¤ëª… ë¬¸ì¥ì´ ìˆì–´ë„ ì²« JSON ì˜¤ë¸Œì íŠ¸ë§Œ ë½‘ê¸° ëª©ì 
    match = re.search(r"\{[\s\S]*\}", cleaned)  # ì¤„ë°”ê¿ˆ í¬í•¨ íƒìƒ‰ ì—­í• 
    if match:
        cleaned = match.group(0)

    # 3) json.loads ì‹œë„ ë° ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ëª©ì  í…ìŠ¤íŠ¸ í•¨ê»˜ ì˜ˆì™¸ ë°˜í™˜ ì—­í• 
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        raise ValueError(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë¬¸: {text[:300]}...")  # ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€ ëª©ì 

        
       

# ================== Multi-turn langchain ëŒ€í™” ê´€ë¦¬ í•¨ìˆ˜ ==================
def _get_or_create_chain(
    user_id: Optional[int], 
    user_context: dict = None,
    first_input: str = None
) -> tuple:
    """
    ì‚¬ìš©ìë³„ë¡œ ëŒ€í™” ì²´ì¸ ìœ ì§€ + ì²« ë¬¸ì¥ ì˜ë„ ë¶„ë¥˜
    
    Args:
        user_id: ì‚¬ìš©ì ID
        user_context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ (ì²« ìš”ì²­ì—ë§Œ ì œê³µ)
        first_input: ì²« ë¬¸ì¥ (ì˜ë„ ë¶„ë¥˜ìš©, ìƒˆ ì„¸ì…˜ì—ë§Œ ì œê³µ)
        
    Returns:
        (chain, context) tuple
    """
    # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ë§¤ë²ˆ ìƒˆ ì²´ì¸
    if user_id is None:
        chain = _create_new_chain(user_context, first_input)
        return chain, user_context
    
    # ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ê¸°ì¡´ ì²´ì¸ ì¬ì‚¬ìš©
    session_key = f"user-{user_id}"
    
    if session_key not in CONVERSATION_MEMORIES:
        # ì²« ëŒ€í™”: ìƒˆ ì²´ì¸ ìƒì„± (ì˜ë„ ë¶„ë¥˜ í¬í•¨)
        has_complete_profile = _check_profile_completeness(user_context)
        intent = classify_user_intent(first_input, has_complete_profile) if first_input else (
            ConversationIntent.PROFILE_BUILDING if not has_complete_profile else ConversationIntent.AD_GENERATION
        )
        chain = _create_new_chain(user_context, first_input)
        CONVERSATION_MEMORIES[session_key] = {
            "chain": chain,
            "user_context": user_context,
            "intent": intent,
            "last_access": datetime.now()
        }
        print(f"âœ… ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„±: {session_key} (ì˜ë„: {intent.value})")
        return chain, user_context
    else:
        # ê¸°ì¡´ ëŒ€í™”: ì €ì¥ëœ ì²´ì¸ ì¬ì‚¬ìš©
        session = CONVERSATION_MEMORIES[session_key]
        session["last_access"] = datetime.now()
        print(f"â™»ï¸  ê¸°ì¡´ ëŒ€í™” ì„¸ì…˜ ì¬ì‚¬ìš©: {session_key}")
        return session["chain"], session["user_context"]


def _check_profile_completeness(context: dict) -> bool:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ê°€ ì¶©ë¶„íˆ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not context or not context.get("memory"):
        return False
    
    memory = context["memory"]
    if not memory or not hasattr(memory, 'marketing_strategy'):
        return False
    
    strategy = memory.marketing_strategy
    if not strategy:
        return False
    
    # í•„ìˆ˜ í•„ë“œ ì²´í¬
    required_fields = [
        strategy.get("target_audience"),
        strategy.get("competitive_advantage"),
        strategy.get("brand_concept")
    ]
    
    return all(field is not None for field in required_fields)


def _format_strategy_info(memory) -> str:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not memory or not hasattr(memory, 'marketing_strategy') or not memory.marketing_strategy:
        return "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"
    
    strategy = memory.marketing_strategy
    lines = []
    
    if strategy.get("target_audience"):
        ta = strategy["target_audience"]
        lines.append(f"- íƒ€ê²Ÿ ê³ ê°: {ta}")
    
    if strategy.get("competitive_advantage"):
        lines.append(f"- ì°¨ë³„í™” í¬ì¸íŠ¸: {strategy['competitive_advantage']}")
    
    if strategy.get("brand_concept"):
        lines.append(f"- ë¸Œëœë“œ ì»¨ì…‰: {strategy['brand_concept']}")
    
    if strategy.get("marketing_goals"):
        lines.append(f"- ë§ˆì¼€íŒ… ëª©í‘œ: {strategy['marketing_goals']}")
    
    return "\n".join(lines) if lines else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"


def _create_new_chain(user_context: dict = None, first_input: str = None) -> ConversationChain:
    """ìƒˆ LangChain ConversationChain ìƒì„± (ì˜ë„ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì„ íƒ)"""
    
    # í”„ë¡œí•„ ì™„ì„± ì—¬ë¶€ í™•ì¸
    has_complete_profile = _check_profile_completeness(user_context)
    
    # ì˜ë„ ë¶„ë¥˜ (ìƒˆ ì„¸ì…˜ì´ê³  first_inputì´ ìˆì„ ë•Œë§Œ)
    if first_input:
        intent = classify_user_intent(first_input, has_complete_profile)
        print(f"ğŸ¯ ê°ì§€ëœ ì˜ë„: {intent.value}")
    else:
        # first_inputì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        intent = ConversationIntent.PROFILE_BUILDING if not has_complete_profile else ConversationIntent.AD_GENERATION
    
    # ì˜ë„ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„ íƒ
    if intent == ConversationIntent.PROFILE_BUILDING:
        template = PROFILE_BUILDING_TEMPLATE
    elif intent == ConversationIntent.INFO_UPDATE:
        template = INFO_UPDATE_TEMPLATE
    elif intent == ConversationIntent.AD_GENERATION:
        template = AD_GENERATION_TEMPLATE
    elif intent == ConversationIntent.ANALYSIS:
        template = ANALYSIS_TEMPLATE
    else:
        template = PROFILE_BUILDING_TEMPLATE
    
    # ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ í¬ë§·íŒ…
    strategy_text = _format_strategy_info(user_context.get("memory") if user_context else None)
    
    # ì˜ë„ì— ë§ëŠ” parser ì„ íƒ
    selected_parser = parser_ad if intent == ConversationIntent.AD_GENERATION else parser_profile
    
    # LangChain LLM ì„¤ì •
    llm = ChatOpenAI(
        model="gpt-4o", 
        temperature=0.7,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    # ë©”ëª¨ë¦¬ ì„¤ì •
    memory = ConversationBufferWindowMemory(
        k=MAX_MEMORY_TURNS,
        memory_key="history"
    )
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = PromptTemplate(
        template=template,
        input_variables=["input"],
        partial_variables={
            "format_instructions": selected_parser.get_format_instructions(),
            "business_type": user_context.get("business_type", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "location": user_context.get("location", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "menu_items": user_context.get("menu_items", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "business_hours": user_context.get("business_hours", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "existing_strategy": strategy_text
        },
    )

    # Conversation Chain ìƒì„±
    chain = ConversationChain(
        llm=llm,
        prompt=prompt,
        memory=memory,
        verbose=False 
    )
    
    return chain


async def generate_conversation_response(
    user_input: str,
    session_key: str,
    is_guest: bool = False,
    user_context: dict = None
) -> DialogueGPTResponse_AD | DialogueGPTResponse_Profile:
    """
    [ë¹„ë™ê¸° ë²„ì „] langchain ì‚¬ìš©í•´ì„œ multi-turn ëŒ€í™” ì‘ë‹µ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        session_key: ì„¸ì…˜ í‚¤ (user-{id} or guest-{uuid})
        is_guest: ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì—¬ë¶€
        user_context: ì‚¬ìš©ì í”„ë¡œí•„ ë° ì¥ê¸° ë©”ëª¨ë¦¬ (ìƒˆ ì„¸ì…˜ì—ë§Œ ì œê³µ)
    
    Returns:
        DialogueGPTResponse: ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ìµœì¢… ì½˜í…ì¸ 
    """
    try:
        # ì„¸ì…˜ ì¬ì‚¬ìš© ë˜ëŠ” ìƒˆ ì„¸ì…˜ ìƒì„±
        if session_key in CONVERSATION_MEMORIES:
            print(f"â™»ï¸  ê¸°ì¡´ ëŒ€í™” ì„¸ì…˜ ì¬ì‚¬ìš©: {session_key}")
            memory_obj = CONVERSATION_MEMORIES[session_key]["memory"]
            chain = CONVERSATION_MEMORIES[session_key]["chain"]
            intent = CONVERSATION_MEMORIES[session_key]["intent"]
            parser = CONVERSATION_MEMORIES[session_key]["parser"]
        else:
            print(f"âœ… ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„±: {session_key}")
            
            # ì¸í…íŠ¸ ê²°ì •
            if is_guest:
                intent = ConversationIntent.GUEST_PROFILE
            elif user_context:
                # ë¡œê·¸ì¸ ì‚¬ìš©ì: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ì™„ì„± ì—¬ë¶€ ì²´í¬
                has_complete_profile = _check_profile_completeness(user_context)
                if has_complete_profile:
                    # í”„ë¡œí•„ ì™„ì„± â†’ ê´‘ê³  ìƒì„± ë˜ëŠ” ì •ë³´ ì—…ë°ì´íŠ¸
                    intent = classify_user_intent(user_input, has_complete_profile=True)
                else:
                    # í”„ë¡œí•„ ë¯¸ì™„ì„± â†’ ìƒì„¸ í”„ë¡œí•„ ìˆ˜ì§‘
                    intent = ConversationIntent.PROFILE_BUILDING
            else:
                # user_context ì—†ìŒ â†’ í”„ë¡œí•„ ìˆ˜ì§‘
                intent = ConversationIntent.PROFILE_BUILDING
            
            print(f"ğŸ¯ ê°ì§€ëœ ì˜ë„: {intent.value}")
            
            # í”„ë¡¬í”„íŠ¸ ë° íŒŒì„œ ì„ íƒ
            if intent == ConversationIntent.GUEST_PROFILE:
                template = GUEST_PROFILE_TEMPLATE
                parser = parser_ad  # ë¹„ë¡œê·¸ì¸ì€ ê´‘ê³  ìƒì„±ìœ¼ë¡œ
            elif intent == ConversationIntent.PROFILE_BUILDING:
                template = PROFILE_BUILDING_TEMPLATE
                parser = parser_profile
            elif intent == ConversationIntent.INFO_UPDATE:
                template = INFO_UPDATE_TEMPLATE
                parser = parser_profile
            elif intent == ConversationIntent.AD_GENERATION:
                template = AD_GENERATION_TEMPLATE
                parser = parser_ad
            else:
                template = PROFILE_BUILDING_TEMPLATE
                parser = parser_profile
            
            # ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ í¬ë§·íŒ…
            strategy_text = _format_strategy_info(user_context.get("memory") if user_context else None)
            
            # LangChain ì„¤ì •
            llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.7,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )
            
            memory_obj = ConversationBufferWindowMemory(
                k=MAX_MEMORY_TURNS,
                memory_key="history",
                return_messages=True
            )
            
            prompt = PromptTemplate(
                template=template,
                input_variables=["input"],
                partial_variables={
                    "format_instructions": parser.get_format_instructions(),
                    "business_type": user_context.get("business_type", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "location": user_context.get("location", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "menu_items": user_context.get("menu_items", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "business_hours": user_context.get("business_hours", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "existing_strategy": strategy_text
                },
            )
            
            chain = ConversationChain(
                llm=llm,
                prompt=prompt,
                memory=memory_obj,
                verbose=False
            )
            
            # ì„¸ì…˜ ì €ì¥
            CONVERSATION_MEMORIES[session_key] = {
                "memory": memory_obj,
                "chain": chain,
                "intent": intent,
                "parser": parser,
                "user_context": user_context
            }
        
        # langchain ì‹¤í–‰(ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬ & í”„ë¡¬í”„íŠ¸ ì£¼ì…) - asyncio.to_thread ì‚¬ìš©
        raw_response = await asyncio.to_thread(
            lambda: chain.invoke(input=user_input)['response'].strip()
        )
        
        # ì˜ë„ ê°€ì ¸ì˜¤ê¸°
        session = CONVERSATION_MEMORIES.get(session_key)
        intent = session.get("intent") if session else ConversationIntent.AD_GENERATION
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (ì´ë¯¸ parserê°€ ì˜¬ë°”ë¥¸ íƒ€ì…ìœ¼ë¡œ íŒŒì‹±í•¨)
        data = _safe_json_from_text(raw_response)
        
        if intent in [ConversationIntent.AD_GENERATION, ConversationIntent.GUEST_PROFILE]:
            # ê´‘ê³  ìƒì„± ëª¨ë“œ (ë¡œê·¸ì¸ AD_GENERATION + ë¹„ë¡œê·¸ì¸ GUEST_PROFILE)
            response = DialogueGPTResponse_AD(**data)
        else:
            # PROFILE_BUILDING, INFO_UPDATE, ANALYSIS
            # GPTê°€ last_mentë¥¼ ì•ˆ ë³´ë‚´ë©´ ê°•ì œ ì£¼ì…
            if data.get("is_complete") and not data.get("last_ment"):
                data["last_ment"] = "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤"
            response = DialogueGPTResponse_Profile(**data)
        
        # ëŒ€í™” ì™„ë£Œ ì‹œ: ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ (ì„¸ì…˜ ì‚­ì œëŠ” gpt.pyì—ì„œ ì²˜ë¦¬)
        if response.is_complete and session_key in CONVERSATION_MEMORIES:
            # ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
            messages = memory_obj.chat_memory.messages
            conversation_history = [
                {
                    "role": "user" if msg.type == "human" else "assistant",
                    "content": msg.content
                }
                for msg in messages
            ]
            response.conversation_history = conversation_history
            print(f"ğŸ“ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ ì™„ë£Œ: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
        
        return response

    except Exception as e:
        raise ValueError(f"LangChain ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")


      
# ë‹¨ì¼ ì½˜í…ì¸  ìƒì„±
async def generate_marketing_idea(prompt_text: str, context=None) -> dict:
    """
    [ë¹„ë™ê¸° ë²„ì „] ë‹¨ì¼ í„´ì—ì„œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„±í•˜ëŠ” ì—­í• 
    - ë§ˆì¼€íŒ… ì•„ì´ë””ì–´/ìº¡ì…˜/í•´ì‹œíƒœê·¸/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—­í• 
    - ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ JSONìœ¼ë¡œ ê°•ì œ ë° ì•ˆì „ íŒŒì‹± ì—­í• 
    """
    #( ê¸°ì¡´ generate_marketing_idea í•¨ìˆ˜ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    
    # 1) ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ êµ¬ì„± ì—­í• 
    system = (
        "ë„ˆëŠ” ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ ì—­í• . "
        "í˜„ì¬ ë‚ ì§œì™€ ê³„ì ˆ ë° ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì•¼ í•¨. "
        "ì˜ˆ: 11ì›”ì´ë©´ ê°€ì„/ê²¨ìš¸ ì´ë²¤íŠ¸, 5ì›”ì´ë©´ ë´„ ì´ë²¤íŠ¸ë¥¼ ì œì•ˆ. "
        "í•­ìƒ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥. ì½”ë“œë¸”ë¡/ì„¤ëª…/ì¶”ê°€ ë¬¸ì¥ ê¸ˆì§€."
    )

    # 2) ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì—­í• 
    user = f"""
    ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œìƒê³µì¸ì„ ìœ„í•œ í™ë³´ ì½˜í…ì¸ ë¥¼ JSON í˜•íƒœë¡œ ìƒì„±í•´ì¤˜.

    ì…ë ¥:
    - ì‚¬ìš©ì ìš”ì²­: {prompt_text}
    - ë§¥ë½ ì •ë³´: {context or 'ë‚ ì”¨, ì—…ì¢…, ë¶„ìœ„ê¸° ë“±'}

    ì¶œë ¥(JSON ì˜¤ë¸Œì íŠ¸ë§Œ, ì¶”ê°€ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ ê¸ˆì§€):
    ì¶œë ¥(JSON í˜•ì‹ìœ¼ë¡œë§Œ, ``json ë¸”ë¡ ì—†ì´):
    {{
     "idea": "ì§§ì€ ì´ë²¤íŠ¸ ì•„ì´ë””ì–´ ë¬¸ì¥",
      "caption": "í™ë³´ìš© ë¬¸êµ¬(ì§§ê³  ê°ì„±ì ì¸ ë¬¸ì¥)",
      "hashtags": ["#ì˜ˆì‹œ", "#í™ë³´", "#ì§€ì—­ëª…"],
      "image_prompt": "Stable Diffusionìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸"
    }}
    """.strip()

    try:
        # 3) Chat Completions í˜¸ì¶œ ì—­í• 
        #    - ê°€ëŠ¥ ëª¨ë¸ì˜ ê²½ìš° JSON ê°•ì œ í¬ë§· ì§€ì • ì—­í• 
        res = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.7,
            # ì§€ì›ë˜ëŠ” ëª¨ë¸ì¸ ê²½ìš°ë§Œ ë™ì‘. ë¯¸ì§€ì›ì´ë©´ ì œê±° í•„ìš”ì„±.
            response_format={"type": "json_object"},
        )

        # 4) ì½˜í…ì¸  ì¶”ì¶œ ë° ë„/ì¸ë±ìŠ¤ ë³´í˜¸ ì—­í• 
        if not res.choices or not res.choices[0].message or not res.choices[0].message.content:
            raise ValueError("ëª¨ë¸ ì‘ë‹µ ë¹„ì •ìƒ: content ì—†ìŒ")

        content = res.choices[0].message.content.strip()
        # 5) ì•ˆì „ íŒŒì‹± ìˆ˜í–‰ ì—­í• 
        data = _safe_json_from_text(content)


        # 6) ìŠ¤í‚¤ë§ˆ ë³´ì •(íƒ€ì…/í•„ë“œ ê¸°ë³¸ê°’ ì±„ìš°ê¸°) ì—­í• 
        idea = data.get("idea", "").strip()
        caption = data.get("caption", "").strip()
        hashtags = data.get("hashtags", [])
        image_prompt = data.get("image_prompt", "").strip()

        if not isinstance(hashtags, list):
            hashtags = []
        # 7) ìµœì†Œ í•„ìˆ˜ê°’ ì ê²€ ì—­í• 
        if not image_prompt:
            # image_prompt ëˆ„ë½ ì‹œ ìº¡ì…˜/ì•„ì´ë””ì–´ ê¸°ë°˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ë³´ì • ì—­í• 
            fallback = "clean promotional poster, high quality, modern typography"
            image_prompt = f"{caption or idea}, {fallback}"

        return {
            "idea": idea,
            "caption": caption,
            "hashtags": hashtags,
            "image_prompt": image_prompt
        }

    except Exception as e:
        # 8) ìµœì¢… ì˜ˆì™¸ ë‹¨ì¼í™” ë° ìƒìœ„ ë ˆì´ì–´ ì „ë‹¬ ì—­í• 
        raise ValueError(f"GPT ìƒì„± ì‹¤íŒ¨: {e}")

async def extract_city_name_english(location: str) -> str:
    """
    [ë¹„ë™ê¸° ë²„ì „] í•œê¸€ ì§€ì—­ëª…ì„ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜
    ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬" -> "Seoul"
        "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬" -> "Busan"
    """
    import re
    
    # ì´ë¯¸ ì˜ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.match(r'^[a-zA-Z\s]+$', location):
        return location.split()[0]  # ì²« ë‹¨ì–´ë§Œ ë°˜í™˜
    
    # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if not location or location.strip() == "":
        return "Seoul"
    
    try:
        prompt = f"""
        ë‹¤ìŒ í•œêµ­ì–´ ì§€ì—­ëª…ì„ ë‚ ì”¨ APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜í•´ì¤˜.
        ë„ì‹œëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ë°˜í™˜í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ('ì„œìš¸ ê°•ë‚¨êµ¬' -> 'Seoul' ì²˜ëŸ¼).
        
        ì…ë ¥: {location}
        ì¶œë ¥ í˜•ì‹: ì˜ì–´ ë„ì‹œëª… (ì˜ˆ: Seoul, Busan, Incheon)
        """
        
        res = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼
            max_tokens=20     # ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
        )
        
        city_name = res.choices[0].message.content.strip()
        
        # ê²°ê³¼ ê²€ì¦ (ì˜ì–´ë§Œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        if re.match(r'^[a-zA-Z\s-]+$', city_name):
            # ì—¬ëŸ¬ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ (ì˜ˆ: "Seoul City" -> "Seoul")
            return city_name.split()[0]
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì´ë©´ ê¸°ë³¸ê°’
            return "Seoul"
            
    except Exception as e:
        print(f"[ì§€ì—­ëª… ë³€í™˜ ì˜¤ë¥˜]: {e}")
        return "Seoul"  # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
