# gpt_service.py
# generat_marketing_idae í•¨ìˆ˜ ìœ ì§€
# langchain ì‚¬ìš© _get_or_create_chain, generate_conversation_response í•¨ìˆ˜ ì¶”ê°€

import os
import json
import re  # ì •ê·œì‹ ì‚¬ìš© ëª©ì 
from typing import Optional, Dict
from datetime import datetime
from enum import Enum
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_classic.chains import ConversationChain
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from backend.app.core.schemas import DialogueGPTResponse, FinalContentSchema

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================== ëŒ€í™” ì˜ë„ ë¶„ë¥˜ ==================

class ConversationIntent(str, Enum):
    """ëŒ€í™” ì˜ë„ ë¶„ë¥˜"""
    PROFILE_BUILDING = "profile_building"  # ì²« ëŒ€í™”: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘
    INFO_UPDATE = "info_update"  # ì •ë³´ ì—…ë°ì´íŠ¸
    AD_GENERATION = "ad_generation"  # ê´‘ê³  ìƒì„±
    ANALYSIS = "analysis"  # ë¶„ì„/ì¡°ì–¸


def classify_user_intent(user_input: str, has_complete_profile: bool) -> ConversationIntent:
    """
    ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        has_complete_profile: í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        
    Returns:
        ConversationIntent
    """
    
    # ì²« ëŒ€í™”ëŠ” ë¬´ì¡°ê±´ í”„ë¡œí•„ ìˆ˜ì§‘
    if not has_complete_profile:
        return ConversationIntent.PROFILE_BUILDING
    
    # ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­
    user_input_lower = user_input.lower()
    
    # ê´‘ê³  ìƒì„± ê´€ë ¨ í‚¤ì›Œë“œ
    ad_keywords = ['ê´‘ê³ ', 'ì´ë¯¸ì§€', 'í¬ìŠ¤í„°', 'í™ë³´', 'ë°°ë„ˆ', 'ë§Œë“¤ì–´', 'ìƒì„±', 'ë””ìì¸', 'ì•„ì´ë””ì–´']
    if any(keyword in user_input_lower for keyword in ad_keywords):
        return ConversationIntent.AD_GENERATION
    
    # ì •ë³´ ì—…ë°ì´íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ
    update_keywords = ['ìš”ì¦˜', 'ìš”ìƒˆ', 'ìµœê·¼', 'ì§€ê¸ˆ', 'ë°”ë€Œ', 'ë³€ê²½', 'ëŠ˜ì—ˆ', 'ì¤„ì—ˆ', 'ë§ì•„', 'ì ì–´', 'ë‹¬ë¼', 'ë‹¤ë¥´']
    if any(keyword in user_input_lower for keyword in update_keywords):
        return ConversationIntent.INFO_UPDATE
    
    # ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ
    analysis_keywords = ['ì™œ', 'ì´ìœ ', 'ë¶„ì„', 'ì–´ë–»ê²Œ', 'ì¶”ì²œ', 'ì¡°ì–¸', 'ë„ì›€']
    if any(keyword in user_input_lower for keyword in analysis_keywords):
        return ConversationIntent.ANALYSIS
    
    # ê¸°ë³¸ê°’: ê´‘ê³  ìƒì„±
    return ConversationIntent.AD_GENERATION

# langchain ë³€ìˆ˜ ì •ì˜
MAX_MEMORY_TURNS = 10
parser = PydanticOutputParser(pydantic_object=DialogueGPTResponse)

# ì‚¬ìš©ìë³„ ëŒ€í™” ì„¸ì…˜ ì €ì¥ (user_id -> {chain, last_access})
CONVERSATION_MEMORIES: Dict[str, Dict] = {}

# ================== í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤ ==================

# 1ï¸âƒ£ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘ í”„ë¡¬í”„íŠ¸ (ì²« ëŒ€í™” ì „ìš©)
PROFILE_BUILDING_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ê¸°ë³¸ ì •ë³´ (ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´) ===
ì—…ì¢…: {business_type}
ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}
ì˜ì—…ì‹œê°„: {business_hours}

=== í˜„ì¬ ìˆ˜ì§‘ëœ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì´ë²ˆì´ ì²« ëŒ€í™”ì´ë¯€ë¡œ, íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ…ì„ ìœ„í•´ ë‹¤ìŒ í•µì‹¬ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì§‘í•˜ì„¸ìš”:

1. **íƒ€ê²Ÿ ê³ ê°** (ì—°ë ¹ëŒ€, ì„±ë³„, ì§ì—…, íŠ¹ì„±)
   - ì˜ˆ: "ì£¼ë¡œ ì–´ë–¤ ê³ ê°ì¸µì´ ë§ì´ ë°©ë¬¸í•˜ì‹œë‚˜ìš”?"
   
2. **ì°¨ë³„í™” í¬ì¸íŠ¸** (ê²½ìŸì—…ì²´ ëŒ€ë¹„ ê°•ì )
   - ì˜ˆ: "ì£¼ë³€ ì¹´í˜ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ íŠ¹ë³„í•œ ê°•ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
   
3. **ë¸Œëœë“œ ì»¨ì…‰** (ì¶”êµ¬í•˜ëŠ” ì´ë¯¸ì§€, ë¶„ìœ„ê¸°)
   - ì˜ˆ: "ì–´ë–¤ ë¶„ìœ„ê¸°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì¶”êµ¬í•˜ì‹œë‚˜ìš”?"
   
4. **ë§ˆì¼€íŒ… ëª©í‘œ** (ì‹ ê·œ ê³ ê° ìœ ì¹˜? ì¬ë°©ë¬¸ ì¦ëŒ€? ë§¤ì¶œ ì¦ê°€?)
   - ì˜ˆ: "í˜„ì¬ ê°€ì¥ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?"

=== ì¤‘ìš” ê·œì¹™ ===
- í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì„¸ìš” (ì—¬ëŸ¬ ì§ˆë¬¸ ë™ì‹œ ê¸ˆì§€)
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™” í†¤ ìœ ì§€
- ì‚¬ìš©ìê°€ ë‹µë³€í•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œë‚˜ ì„ íƒì§€ ì œê³µ
- ìœ„ 4ê°€ì§€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ is_complete=true ì„¤ì •
- ê¸°ë³¸ ì •ë³´(ì—…ì¢…, ìœ„ì¹˜, ë©”ë‰´ ë“±)ëŠ” ì ˆëŒ€ ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 2ï¸âƒ£ ì •ë³´ ì—…ë°ì´íŠ¸ í”„ë¡¬í”„íŠ¸ (í‹€ë§Œ)
INFO_UPDATE_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== í˜„ì¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.
(ì´ í”„ë¡¬í”„íŠ¸ëŠ” í–¥í›„ êµ¬í˜„ ì˜ˆì •)

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 3ï¸âƒ£ ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸ (í‹€ë§Œ)
AD_GENERATION_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê´‘ê³ /ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.
(ì´ í”„ë¡¬í”„íŠ¸ëŠ” í–¥í›„ êµ¬í˜„ ì˜ˆì •)

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 4ï¸âƒ£ ë¶„ì„/ì¡°ì–¸ í”„ë¡¬í”„íŠ¸ (í‹€ë§Œ)
ANALYSIS_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
(ì´ í”„ë¡¬í”„íŠ¸ëŠ” í–¥í›„ êµ¬í˜„ ì˜ˆì •)

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""


def _safe_json_from_text(text: str) -> dict:
    """
    ëª¨ë¸ì´ ```json ... ``` ê°™ì€ ì½”ë“œë¸”ë¡ì„ ì„ì–´ ë³´ë‚´ê±°ë‚˜
    ìì—°ì–´ê°€ í•¨ê»˜ í¬í•¨ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•œ ì•ˆì „ íŒŒì„œ ì—­í• 
    """
    # 1) ì½”ë“œíœìŠ¤ ì œê±° ì‹œë„ ì—­í• 
    cleaned = text.replace("```json", "").replace("```", "").strip()

    # 2) ì •ê·œì‹ìœ¼ë¡œ ê°€ì¥ ë°”ê¹¥ { ... } ê°ì²´ë§Œ ì¶”ì¶œ ì‹œë„ ì—­í• 
    #    - ì¤‘ê°„ì— ì„¤ëª… ë¬¸ì¥ì´ ìˆì–´ë„ ì²« JSON ì˜¤ë¸Œì íŠ¸ë§Œ ë½‘ê¸° ëª©ì 
    match = re.search(r"\{[\s\S]*\}", cleaned)  # ì¤„ë°”ê¿ˆ í¬í•¨ íƒìƒ‰ ì—­í• 
    if match:
        cleaned = match.group(0)

    # 3) json.loads ì‹œë„ ë° ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ëª©ì  í…ìŠ¤íŠ¸ í•¨ê»˜ ì˜ˆì™¸ ë°˜í™˜ ì—­í• 
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        raise ValueError(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë¬¸: {text[:300]}...")  # ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€ ëª©ì 

        
       

# ================== Multi-turn langchain ëŒ€í™” ê´€ë¦¬ í•¨ìˆ˜ ==================
def _get_or_create_chain(
    user_id: Optional[int], 
    user_context: dict = None,
    first_input: str = None
) -> tuple:
    """
    ì‚¬ìš©ìë³„ë¡œ ëŒ€í™” ì²´ì¸ ìœ ì§€ + ì²« ë¬¸ì¥ ì˜ë„ ë¶„ë¥˜
    
    Args:
        user_id: ì‚¬ìš©ì ID
        user_context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ (ì²« ìš”ì²­ì—ë§Œ ì œê³µ)
        first_input: ì²« ë¬¸ì¥ (ì˜ë„ ë¶„ë¥˜ìš©, ìƒˆ ì„¸ì…˜ì—ë§Œ ì œê³µ)
        
    Returns:
        (chain, context) tuple
    """
    # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ë§¤ë²ˆ ìƒˆ ì²´ì¸
    if user_id is None:
        chain = _create_new_chain(user_context, first_input)
        return chain, user_context
    
    # ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ê¸°ì¡´ ì²´ì¸ ì¬ì‚¬ìš©
    session_key = f"user-{user_id}"
    
    if session_key not in CONVERSATION_MEMORIES:
        # ì²« ëŒ€í™”: ìƒˆ ì²´ì¸ ìƒì„± (ì˜ë„ ë¶„ë¥˜ í¬í•¨)
        chain = _create_new_chain(user_context, first_input)
        CONVERSATION_MEMORIES[session_key] = {
            "chain": chain,
            "user_context": user_context,
            "last_access": datetime.now()
        }
        print(f"âœ… ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„±: {session_key}")
        return chain, user_context
    else:
        # ê¸°ì¡´ ëŒ€í™”: ì €ì¥ëœ ì²´ì¸ ì¬ì‚¬ìš©
        session = CONVERSATION_MEMORIES[session_key]
        session["last_access"] = datetime.now()
        print(f"â™»ï¸  ê¸°ì¡´ ëŒ€í™” ì„¸ì…˜ ì¬ì‚¬ìš©: {session_key}")
        return session["chain"], session["user_context"]


def _check_profile_completeness(context: dict) -> bool:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ê°€ ì¶©ë¶„íˆ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not context or not context.get("memory"):
        return False
    
    memory = context["memory"]
    if not memory or not hasattr(memory, 'marketing_strategy'):
        return False
    
    strategy = memory.marketing_strategy
    if not strategy:
        return False
    
    # í•„ìˆ˜ í•„ë“œ ì²´í¬
    required_fields = [
        strategy.get("target_audience"),
        strategy.get("competitive_advantage"),
        strategy.get("brand_concept")
    ]
    
    return all(field is not None for field in required_fields)


def _format_strategy_info(memory) -> str:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not memory or not hasattr(memory, 'marketing_strategy') or not memory.marketing_strategy:
        return "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"
    
    strategy = memory.marketing_strategy
    lines = []
    
    if strategy.get("target_audience"):
        ta = strategy["target_audience"]
        lines.append(f"- íƒ€ê²Ÿ ê³ ê°: {ta}")
    
    if strategy.get("competitive_advantage"):
        lines.append(f"- ì°¨ë³„í™” í¬ì¸íŠ¸: {strategy['competitive_advantage']}")
    
    if strategy.get("brand_concept"):
        lines.append(f"- ë¸Œëœë“œ ì»¨ì…‰: {strategy['brand_concept']}")
    
    if strategy.get("marketing_goals"):
        lines.append(f"- ë§ˆì¼€íŒ… ëª©í‘œ: {strategy['marketing_goals']}")
    
    return "\n".join(lines) if lines else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"


def _create_new_chain(user_context: dict = None, first_input: str = None) -> ConversationChain:
    """ìƒˆ LangChain ConversationChain ìƒì„± (ì˜ë„ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì„ íƒ)"""
    
    # í”„ë¡œí•„ ì™„ì„± ì—¬ë¶€ í™•ì¸
    has_complete_profile = _check_profile_completeness(user_context)
    
    # ì˜ë„ ë¶„ë¥˜ (ìƒˆ ì„¸ì…˜ì´ê³  first_inputì´ ìˆì„ ë•Œë§Œ)
    if first_input:
        intent = classify_user_intent(first_input, has_complete_profile)
        print(f"ğŸ¯ ê°ì§€ëœ ì˜ë„: {intent.value}")
    else:
        # first_inputì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        intent = ConversationIntent.PROFILE_BUILDING if not has_complete_profile else ConversationIntent.AD_GENERATION
    
    # ì˜ë„ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„ íƒ
    if intent == ConversationIntent.PROFILE_BUILDING:
        template = PROFILE_BUILDING_TEMPLATE
    elif intent == ConversationIntent.INFO_UPDATE:
        template = INFO_UPDATE_TEMPLATE
    elif intent == ConversationIntent.AD_GENERATION:
        template = AD_GENERATION_TEMPLATE
    elif intent == ConversationIntent.ANALYSIS:
        template = ANALYSIS_TEMPLATE
    else:
        template = PROFILE_BUILDING_TEMPLATE
    
    # ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ í¬ë§·íŒ…
    strategy_text = _format_strategy_info(user_context.get("memory") if user_context else None)
    
    # LangChain LLM ì„¤ì •
    llm = ChatOpenAI(
        model="gpt-4o", 
        temperature=0.7,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    # ë©”ëª¨ë¦¬ ì„¤ì •
    memory = ConversationBufferWindowMemory(
        k=MAX_MEMORY_TURNS,
        memory_key="history"
    )
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = PromptTemplate(
        template=template,
        input_variables=["input"],
        partial_variables={
            "format_instructions": parser.get_format_instructions(),
            "business_type": user_context.get("business_type", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "location": user_context.get("location", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "menu_items": user_context.get("menu_items", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "business_hours": user_context.get("business_hours", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
            "existing_strategy": strategy_text
        },
    )

    # Conversation Chain ìƒì„±
    chain = ConversationChain(
        llm=llm,
        prompt=prompt,
        memory=memory,
        verbose=False 
    )
    
    return chain


def generate_conversation_response(
    user_input: str,
    user_id: Optional[int] = None,
    user_context: dict = None
) -> DialogueGPTResponse:
    """
    langchain ì‚¬ìš©í•´ì„œ multi-turn ëŒ€í™” ì‘ë‹µ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        user_id: ì‚¬ìš©ì ID (ë¡œê·¸ì¸í•œ ê²½ìš°)
        user_context: ì‚¬ìš©ì í”„ë¡œí•„ ë° ì¥ê¸° ë©”ëª¨ë¦¬ (ìƒˆ ì„¸ì…˜ì—ë§Œ ì œê³µ)
    
    Returns:
        DialogueGPTResponse: ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ìµœì¢… ì½˜í…ì¸ 
    """
    try:
        # ìƒˆ ì„¸ì…˜ ì—¬ë¶€ í™•ì¸
        session_key = f"user-{user_id}" if user_id else "anonymous"
        is_new_session = session_key not in CONVERSATION_MEMORIES
        
        # ì²´ì¸ ë¡œë“œ ë˜ëŠ” ìƒì„± (ìƒˆ ì„¸ì…˜ì´ê³  user_idê°€ ìˆì„ ë•Œë§Œ first_input ì „ë‹¬)
        chain, context = _get_or_create_chain(
            user_id,
            user_context,
            first_input=user_input if (is_new_session and user_id) else None
        )
        
        # langchain ì‹¤í–‰(ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬ & í”„ë¡¬í”„íŠ¸ ì£¼ì…)
        raw_response = chain.invoke(input=user_input)['response'].strip()
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ & ìœ íš¨ì„± ê²€ì‚¬
        data = _safe_json_from_text(raw_response)
        response = DialogueGPTResponse(**data)
        
        # ëŒ€í™” ì™„ë£Œ ì‹œ: ì„¸ì…˜ ì‚­ì œ ì „ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
        if response.is_complete:
            if user_id and session_key in CONVERSATION_MEMORIES:
                # ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
                messages = chain.memory.chat_memory.messages
                conversation_history = [
                    {
                        "role": "user" if msg.type == "human" else "assistant",
                        "content": msg.content
                    }
                    for msg in messages
                ]
                response.conversation_history = conversation_history
                print(f"ğŸ“ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ ì™„ë£Œ: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
                
                # ì„¸ì…˜ ì‚­ì œ
                del CONVERSATION_MEMORIES[session_key]
                print(f"ğŸ—‘ï¸  ëŒ€í™” ì™„ë£Œ, ì„¸ì…˜ ì‚­ì œ: {session_key}")
        
        return response

    except Exception as e:
        raise ValueError(f"LangChain ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")


      
# ë‹¨ì¼ ì½˜í…ì¸  ìƒì„±
def generate_marketing_idea(prompt_text: str, context=None) -> dict:
    """
    [ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€] ë‹¨ì¼ í„´ì—ì„œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„±í•˜ëŠ” ì—­í• 
    - ë§ˆì¼€íŒ… ì•„ì´ë””ì–´/ìº¡ì…˜/í•´ì‹œíƒœê·¸/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—­í• 
    - ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ JSONìœ¼ë¡œ ê°•ì œ ë° ì•ˆì „ íŒŒì‹± ì—­í• 
    """
    #( ê¸°ì¡´ generate_marketing_idea í•¨ìˆ˜ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    
    # 1) ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ êµ¬ì„± ì—­í• 
    system = (
        "ë„ˆëŠ” ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ ì—­í• . "
        "í˜„ì¬ ë‚ ì§œì™€ ê³„ì ˆ ë° ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì•¼ í•¨. "
        "ì˜ˆ: 11ì›”ì´ë©´ ê°€ì„/ê²¨ìš¸ ì´ë²¤íŠ¸, 5ì›”ì´ë©´ ë´„ ì´ë²¤íŠ¸ë¥¼ ì œì•ˆ. "
        "í•­ìƒ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥. ì½”ë“œë¸”ë¡/ì„¤ëª…/ì¶”ê°€ ë¬¸ì¥ ê¸ˆì§€."
    )

    # 2) ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì—­í• 
    user = f"""
    ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œìƒê³µì¸ì„ ìœ„í•œ í™ë³´ ì½˜í…ì¸ ë¥¼ JSON í˜•íƒœë¡œ ìƒì„±í•´ì¤˜.

    ì…ë ¥:
    - ì‚¬ìš©ì ìš”ì²­: {prompt_text}
    - ë§¥ë½ ì •ë³´: {context or 'ë‚ ì”¨, ì—…ì¢…, ë¶„ìœ„ê¸° ë“±'}

    ì¶œë ¥(JSON ì˜¤ë¸Œì íŠ¸ë§Œ, ì¶”ê°€ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ ê¸ˆì§€):
    ì¶œë ¥(JSON í˜•ì‹ìœ¼ë¡œë§Œ, ``json ë¸”ë¡ ì—†ì´):
    {{
     "idea": "ì§§ì€ ì´ë²¤íŠ¸ ì•„ì´ë””ì–´ ë¬¸ì¥",
      "caption": "í™ë³´ìš© ë¬¸êµ¬(ì§§ê³  ê°ì„±ì ì¸ ë¬¸ì¥)",
      "hashtags": ["#ì˜ˆì‹œ", "#í™ë³´", "#ì§€ì—­ëª…"],
      "image_prompt": "Stable Diffusionìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸"
    }}
    """.strip()

    try:
        # 3) Chat Completions í˜¸ì¶œ ì—­í• 
        #    - ê°€ëŠ¥ ëª¨ë¸ì˜ ê²½ìš° JSON ê°•ì œ í¬ë§· ì§€ì • ì—­í• 
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.7,
            # ì§€ì›ë˜ëŠ” ëª¨ë¸ì¸ ê²½ìš°ë§Œ ë™ì‘. ë¯¸ì§€ì›ì´ë©´ ì œê±° í•„ìš”ì„±.
            response_format={"type": "json_object"},
        )

        # 4) ì½˜í…ì¸  ì¶”ì¶œ ë° ë„/ì¸ë±ìŠ¤ ë³´í˜¸ ì—­í• 
        if not res.choices or not res.choices[0].message or not res.choices[0].message.content:
            raise ValueError("ëª¨ë¸ ì‘ë‹µ ë¹„ì •ìƒ: content ì—†ìŒ")

        content = res.choices[0].message.content.strip()
        # 5) ì•ˆì „ íŒŒì‹± ìˆ˜í–‰ ì—­í• 
        data = _safe_json_from_text(content)


        # 6) ìŠ¤í‚¤ë§ˆ ë³´ì •(íƒ€ì…/í•„ë“œ ê¸°ë³¸ê°’ ì±„ìš°ê¸°) ì—­í• 
        idea = data.get("idea", "").strip()
        caption = data.get("caption", "").strip()
        hashtags = data.get("hashtags", [])
        image_prompt = data.get("image_prompt", "").strip()

        if not isinstance(hashtags, list):
            hashtags = []
        # 7) ìµœì†Œ í•„ìˆ˜ê°’ ì ê²€ ì—­í• 
        if not image_prompt:
            # image_prompt ëˆ„ë½ ì‹œ ìº¡ì…˜/ì•„ì´ë””ì–´ ê¸°ë°˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ë³´ì • ì—­í• 
            fallback = "clean promotional poster, high quality, modern typography"
            image_prompt = f"{caption or idea}, {fallback}"

        return {
            "idea": idea,
            "caption": caption,
            "hashtags": hashtags,
            "image_prompt": image_prompt
        }

    except Exception as e:
        # 8) ìµœì¢… ì˜ˆì™¸ ë‹¨ì¼í™” ë° ìƒìœ„ ë ˆì´ì–´ ì „ë‹¬ ì—­í• 
        raise ValueError(f"GPT ìƒì„± ì‹¤íŒ¨: {e}")

        
    # ë„ì‹œëª… ë³€í™˜(ì •ê·œí™”)
    match = re.search(r"\{[\s\S]*\}", content)
    if match:
        json_str = match.group()
    else:
        json_str = content

    try:
        result = json.loads(json_str)
    except json.JSONDecodeError:
        result = {"idea": content, "caption": content, "hashtags": [], "image_prompt": ""}
    return result

def extract_city_name_english(location: str) -> str:
    """
    í•œê¸€ ì§€ì—­ëª…ì„ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜
    ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬" -> "Seoul"
        "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬" -> "Busan"
    """
    import re
    
    # ì´ë¯¸ ì˜ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.match(r'^[a-zA-Z\s]+$', location):
        return location.split()[0]  # ì²« ë‹¨ì–´ë§Œ ë°˜í™˜
    
    # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if not location or location.strip() == "":
        return "Seoul"
    
    try:
        prompt = f"""
        ë‹¤ìŒ í•œêµ­ì–´ ì§€ì—­ëª…ì„ ë‚ ì”¨ APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜í•´ì¤˜.
        ë„ì‹œëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ë°˜í™˜í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ('ì„œìš¸ ê°•ë‚¨êµ¬' -> 'Seoul' ì²˜ëŸ¼).
        
        ì…ë ¥: {location}
        ì¶œë ¥ í˜•ì‹: ì˜ì–´ ë„ì‹œëª… (ì˜ˆ: Seoul, Busan, Incheon)
        """
        
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼
            max_tokens=20     # ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
        )
        
        city_name = res.choices[0].message.content.strip()
        
        # ê²°ê³¼ ê²€ì¦ (ì˜ì–´ë§Œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        if re.match(r'^[a-zA-Z\s-]+$', city_name):
            # ì—¬ëŸ¬ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ (ì˜ˆ: "Seoul City" -> "Seoul")
            return city_name.split()[0]
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì´ë©´ ê¸°ë³¸ê°’
            return "Seoul"
            
    except Exception as e:
        print(f"[ì§€ì—­ëª… ë³€í™˜ ì˜¤ë¥˜]: {e}")
        return "Seoul"  # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
