# gpt_service.py
# generat_marketing_idae í•¨ìˆ˜ ìœ ì§€
# langchain ì‚¬ìš© _get_or_create_chain, generate_conversation_response í•¨ìˆ˜ ì¶”ê°€

import os
import json
import re  # ì •ê·œì‹ ì‚¬ìš© ëª©ì 
from typing import Optional, Dict
from datetime import datetime
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_classic.chains import ConversationChain
from langchain_classic.memory import ConversationBufferWindowMemory
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from backend.app.core.schemas import DialogueGPTResponse, FinalContentSchema

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# langchain ë³€ìˆ˜ ì •ì˜
MAX_MEMORY_TURNS = 5
parser = PydanticOutputParser(pydantic_object=DialogueGPTResponse)

# ì‚¬ìš©ìë³„ ëŒ€í™” ì„¸ì…˜ ì €ì¥ (user_id -> {chain, last_access})
CONVERSATION_MEMORIES: Dict[str, Dict] = {}

# Multi-turn ëŒ€í™” ê´€ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì—­í•  : ëŒ€í™” ëª©í‘œ, ì‘ë‹µ í˜•ì‹ ì§€ì‹œ
DIALOGUE_TEMPLATE = """
ë„ˆëŠ” ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ ì—­í• ì„ í•œë‹¤.
ë„ˆì˜ ëª©í‘œëŠ” 'ì—…ì¢…', 'í™ë³´ ëª©ì ', 'ë©”ë‰´/ì œí’ˆëª…', 'ì›í•˜ëŠ” ë¶„ìœ„ê¸°', 'íŠ¹ë³„í•œ í–‰ì‚¬/ì´ë²¤íŠ¸' ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´ ìµœì¢… ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤.

{user_info}

í˜„ì¬ ëŒ€í™” ê¸°ë¡:
{history}

ì‚¬ìš©ìì˜ ìƒˆë¡œìš´ ì…ë ¥ì— ëŒ€í•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•œë‹¤.
{format_instructions}

ì‚¬ìš©ì: {input}
AI ì‘ë‹µ:
"""


def _safe_json_from_text(text: str) -> dict:
    """
    ëª¨ë¸ì´ ```json ... ``` ê°™ì€ ì½”ë“œë¸”ë¡ì„ ì„ì–´ ë³´ë‚´ê±°ë‚˜
    ìì—°ì–´ê°€ í•¨ê»˜ í¬í•¨ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•œ ì•ˆì „ íŒŒì„œ ì—­í• 
    """
    # 1) ì½”ë“œíœìŠ¤ ì œê±° ì‹œë„ ì—­í• 
    cleaned = text.replace("```json", "").replace("```", "").strip()

    # 2) ì •ê·œì‹ìœ¼ë¡œ ê°€ì¥ ë°”ê¹¥ { ... } ê°ì²´ë§Œ ì¶”ì¶œ ì‹œë„ ì—­í• 
    #    - ì¤‘ê°„ì— ì„¤ëª… ë¬¸ì¥ì´ ìˆì–´ë„ ì²« JSON ì˜¤ë¸Œì íŠ¸ë§Œ ë½‘ê¸° ëª©ì 
    match = re.search(r"\{[\s\S]*\}", cleaned)  # ì¤„ë°”ê¿ˆ í¬í•¨ íƒìƒ‰ ì—­í• 
    if match:
        cleaned = match.group(0)

    # 3) json.loads ì‹œë„ ë° ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ëª©ì  í…ìŠ¤íŠ¸ í•¨ê»˜ ì˜ˆì™¸ ë°˜í™˜ ì—­í• 
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        raise ValueError(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë¬¸: {text[:300]}...")  # ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€ ëª©ì 

        
       

# ================== Multi-turn langchain ëŒ€í™” ê´€ë¦¬ í•¨ìˆ˜ ==================
def _get_or_create_chain(user_id: Optional[int], user_context: dict = None) -> ConversationChain:
    """
    ì‚¬ìš©ìë³„ë¡œ ëŒ€í™” ì²´ì¸ ìœ ì§€ (user_context ìºì‹±)
    
    - ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì(user_id=None): ë§¤ë²ˆ ìƒˆ ì²´ì¸ ìƒì„±
    - ë¡œê·¸ì¸ ì‚¬ìš©ì: ê¸°ì¡´ ì²´ì¸ ì¬ì‚¬ìš© (user_contextë„ ì„¸ì…˜ì— ì €ì¥)
    """
    # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ë§¤ë²ˆ ìƒˆ ì²´ì¸
    if user_id is None:
        return _create_new_chain(user_context)
    
    # ë¡œê·¸ì¸ ì‚¬ìš©ìëŠ” ê¸°ì¡´ ì²´ì¸ ì¬ì‚¬ìš©
    session_key = f"user-{user_id}"
    
    if session_key not in CONVERSATION_MEMORIES:
        # ì²« ëŒ€í™”: ìƒˆ ì²´ì¸ ìƒì„± ë° ì»¨í…ìŠ¤íŠ¸ ìºì‹±
        chain = _create_new_chain(user_context)
        CONVERSATION_MEMORIES[session_key] = {
            "chain": chain,
            "user_context": user_context,  # ì»¨í…ìŠ¤íŠ¸ ìºì‹±
            "last_access": datetime.now()
        }
        print(f"âœ… ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ìºì‹±): {session_key}")
    else:
        # ê¸°ì¡´ ëŒ€í™”: ì €ì¥ëœ ì²´ì¸ ì¬ì‚¬ìš©
        CONVERSATION_MEMORIES[session_key]["last_access"] = datetime.now()
        print(f"â™»ï¸  ê¸°ì¡´ ëŒ€í™” ì„¸ì…˜ ì¬ì‚¬ìš© (DB ì¿¼ë¦¬ ìŠ¤í‚µ): {session_key}")
    
    return CONVERSATION_MEMORIES[session_key]["chain"]


def _create_new_chain(user_context: dict = None) -> ConversationChain:
    """ìƒˆ LangChain ConversationChain ìƒì„±"""
    # ì‚¬ìš©ì ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜
    user_info = ""
    if user_context:
        info_parts = []
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´
        if user_context.get("business_type"):
            info_parts.append(f"ì—…ì¢…: {user_context['business_type']} (ì´ë¯¸ ì•Œê³  ìˆìŒ, ë‹¤ì‹œ ë¬»ì§€ ë§ˆ)")
        if user_context.get("location"):
            info_parts.append(f"ìœ„ì¹˜: {user_context['location']}")
        if user_context.get("menu_items"):
            info_parts.append(f"ë©”ë‰´/ì œí’ˆ: {user_context['menu_items']} (ì´ë¯¸ ì•Œê³  ìˆìŒ, ë‹¤ì‹œ ë¬»ì§€ ë§ˆ)")
        if user_context.get("business_hours"):
            info_parts.append(f"ì˜ì—…ì‹œê°„: {user_context['business_hours']}")
        
        # ì¥ê¸° ë©”ëª¨ë¦¬ ì¶”ê°€
        if user_context.get("memory"):
            info_parts.append(f"\n=== ì´ì „ ëŒ€í™”ì—ì„œ íŒŒì•…í•œ ì •ë³´ ===\n{user_context['memory']}")
        
        if info_parts:
            user_info = "ì‚¬ìš©ì ì •ë³´ (ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´, ë‹¤ì‹œ ë¬»ì§€ ë§ ê²ƒ):\n" + "\n".join(info_parts)
    
    # LangChain LLM ì„¤ì •
    llm = ChatOpenAI(
        model="gpt-4o-mini", 
        temperature=0.7,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    # ë©”ëª¨ë¦¬ ì„¤ì • (MAX_MEMORY_TURNS ë§Œí¼ ê¸°ì–µ)
    memory = ConversationBufferWindowMemory(
        k=MAX_MEMORY_TURNS,
        memory_key="history"
    )
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = PromptTemplate(
        template=DIALOGUE_TEMPLATE,
        input_variables=["input"], # historyëŠ” memoryê°€ ê´€ë¦¬
        partial_variables={
            "format_instructions": parser.get_format_instructions(),
            "user_info": user_info if user_info else "ì‚¬ìš©ì ì •ë³´ ì—†ìŒ (ëª¨ë“  ì •ë³´ë¥¼ ì§ˆë¬¸í•´ì•¼ í•¨)"
        },
    )

    # Conversation Chain ìƒì„±
    chain = ConversationChain(
        llm=llm,
        prompt=prompt,
        memory=memory,
        verbose=False 
    )
    
    return chain


def generate_conversation_response(
    user_input: str,
    user_id: Optional[int] = None,
    user_context: dict = None
) -> DialogueGPTResponse:
    """
    langchain ì‚¬ìš©í•´ì„œ multi-turn ëŒ€í™” ì‘ë‹µ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        user_id: ì‚¬ìš©ì ID (ë¡œê·¸ì¸í•œ ê²½ìš°)
        user_context: ì‚¬ìš©ì í”„ë¡œí•„ ë° ì¥ê¸° ë©”ëª¨ë¦¬
    
    Returns:
        DialogueGPTResponse: ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ìµœì¢… ì½˜í…ì¸ 
    """
    try:
        # ì‚¬ìš©ìë³„ ì²´ì¸ ê°€ì ¸ì˜¤ê¸° (ë˜ëŠ” ìƒì„±)
        chain = _get_or_create_chain(user_id, user_context)
        
        # langchain ì‹¤í–‰(ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬ & í”„ë¡¬í”„íŠ¸ ì£¼ì…)
        raw_response = chain.invoke(input=user_input)['response'].strip()
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ & ìœ íš¨ì„± ê²€ì‚¬
        data = _safe_json_from_text(raw_response)
        response = DialogueGPTResponse(**data)
        
        # ëŒ€í™” ì™„ë£Œ ì‹œ: ì„¸ì…˜ ì‚­ì œ ì „ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ (ë¡œê·¸ì¸ ì‚¬ìš©ìë§Œ)
        if response.is_complete and user_id:
            session_key = f"user-{user_id}"
            if session_key in CONVERSATION_MEMORIES:
                # ì„¸ì…˜ ì‚­ì œ ì „ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
                chain = CONVERSATION_MEMORIES[session_key]["chain"]
                messages = chain.memory.chat_memory.messages
                
                # LangChain ë©”ì‹œì§€ë¥¼ dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                conversation_history = [
                    {
                        "role": "user" if msg.type == "human" else "assistant",
                        "content": msg.content
                    }
                    for msg in messages
                ]
                response.conversation_history = conversation_history
                print(f"ğŸ“ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ ì™„ë£Œ: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
                
                # ì„¸ì…˜ ì‚­ì œ
                del CONVERSATION_MEMORIES[session_key]
                print(f"ğŸ—‘ï¸  ëŒ€í™” ì™„ë£Œ, ì„¸ì…˜ ì‚­ì œ (ì²´ì¸ + ìºì‹±ëœ ì»¨í…ìŠ¤íŠ¸): {session_key}")
        
        return response

    except Exception as e:
        raise ValueError(f"LangChain ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")


      
# ë‹¨ì¼ ì½˜í…ì¸  ìƒì„±
def generate_marketing_idea(prompt_text: str, context=None) -> dict:
    """
    [ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€] ë‹¨ì¼ í„´ì—ì„œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„±í•˜ëŠ” ì—­í• 
    - ë§ˆì¼€íŒ… ì•„ì´ë””ì–´/ìº¡ì…˜/í•´ì‹œíƒœê·¸/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—­í• 
    - ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ JSONìœ¼ë¡œ ê°•ì œ ë° ì•ˆì „ íŒŒì‹± ì—­í• 
    """
    #( ê¸°ì¡´ generate_marketing_idea í•¨ìˆ˜ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    
    # 1) ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ êµ¬ì„± ì—­í• 
    system = (
        "ë„ˆëŠ” ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ ì—­í• . "
        "í˜„ì¬ ë‚ ì§œì™€ ê³„ì ˆ ë° ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì•¼ í•¨. "
        "ì˜ˆ: 11ì›”ì´ë©´ ê°€ì„/ê²¨ìš¸ ì´ë²¤íŠ¸, 5ì›”ì´ë©´ ë´„ ì´ë²¤íŠ¸ë¥¼ ì œì•ˆ. "
        "í•­ìƒ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥. ì½”ë“œë¸”ë¡/ì„¤ëª…/ì¶”ê°€ ë¬¸ì¥ ê¸ˆì§€."
    )

    # 2) ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì—­í• 
    user = f"""
    ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œìƒê³µì¸ì„ ìœ„í•œ í™ë³´ ì½˜í…ì¸ ë¥¼ JSON í˜•íƒœë¡œ ìƒì„±í•´ì¤˜.

    ì…ë ¥:
    - ì‚¬ìš©ì ìš”ì²­: {prompt_text}
    - ë§¥ë½ ì •ë³´: {context or 'ë‚ ì”¨, ì—…ì¢…, ë¶„ìœ„ê¸° ë“±'}

    ì¶œë ¥(JSON ì˜¤ë¸Œì íŠ¸ë§Œ, ì¶”ê°€ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ ê¸ˆì§€):
    ì¶œë ¥(JSON í˜•ì‹ìœ¼ë¡œë§Œ, ``json ë¸”ë¡ ì—†ì´):
    {{
     "idea": "ì§§ì€ ì´ë²¤íŠ¸ ì•„ì´ë””ì–´ ë¬¸ì¥",
      "caption": "í™ë³´ìš© ë¬¸êµ¬(ì§§ê³  ê°ì„±ì ì¸ ë¬¸ì¥)",
      "hashtags": ["#ì˜ˆì‹œ", "#í™ë³´", "#ì§€ì—­ëª…"],
      "image_prompt": "Stable Diffusionìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸"
    }}
    """.strip()

    try:
        # 3) Chat Completions í˜¸ì¶œ ì—­í• 
        #    - ê°€ëŠ¥ ëª¨ë¸ì˜ ê²½ìš° JSON ê°•ì œ í¬ë§· ì§€ì • ì—­í• 
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.7,
            # ì§€ì›ë˜ëŠ” ëª¨ë¸ì¸ ê²½ìš°ë§Œ ë™ì‘. ë¯¸ì§€ì›ì´ë©´ ì œê±° í•„ìš”ì„±.
            response_format={"type": "json_object"},
        )

        # 4) ì½˜í…ì¸  ì¶”ì¶œ ë° ë„/ì¸ë±ìŠ¤ ë³´í˜¸ ì—­í• 
        if not res.choices or not res.choices[0].message or not res.choices[0].message.content:
            raise ValueError("ëª¨ë¸ ì‘ë‹µ ë¹„ì •ìƒ: content ì—†ìŒ")

        content = res.choices[0].message.content.strip()
        # 5) ì•ˆì „ íŒŒì‹± ìˆ˜í–‰ ì—­í• 
        data = _safe_json_from_text(content)


        # 6) ìŠ¤í‚¤ë§ˆ ë³´ì •(íƒ€ì…/í•„ë“œ ê¸°ë³¸ê°’ ì±„ìš°ê¸°) ì—­í• 
        idea = data.get("idea", "").strip()
        caption = data.get("caption", "").strip()
        hashtags = data.get("hashtags", [])
        image_prompt = data.get("image_prompt", "").strip()

        if not isinstance(hashtags, list):
            hashtags = []
        # 7) ìµœì†Œ í•„ìˆ˜ê°’ ì ê²€ ì—­í• 
        if not image_prompt:
            # image_prompt ëˆ„ë½ ì‹œ ìº¡ì…˜/ì•„ì´ë””ì–´ ê¸°ë°˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ë³´ì • ì—­í• 
            fallback = "clean promotional poster, high quality, modern typography"
            image_prompt = f"{caption or idea}, {fallback}"

        return {
            "idea": idea,
            "caption": caption,
            "hashtags": hashtags,
            "image_prompt": image_prompt
        }

    except Exception as e:
        # 8) ìµœì¢… ì˜ˆì™¸ ë‹¨ì¼í™” ë° ìƒìœ„ ë ˆì´ì–´ ì „ë‹¬ ì—­í• 
        raise ValueError(f"GPT ìƒì„± ì‹¤íŒ¨: {e}")

        
    # ë„ì‹œëª… ë³€í™˜(ì •ê·œí™”)
    match = re.search(r"\{[\s\S]*\}", content)
    if match:
        json_str = match.group()
    else:
        json_str = content

    try:
        result = json.loads(json_str)
    except json.JSONDecodeError:
        result = {"idea": content, "caption": content, "hashtags": [], "image_prompt": ""}
    return result

def extract_city_name_english(location: str) -> str:
    """
    í•œê¸€ ì§€ì—­ëª…ì„ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜
    ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬" -> "Seoul"
        "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬" -> "Busan"
    """
    import re
    
    # ì´ë¯¸ ì˜ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.match(r'^[a-zA-Z\s]+$', location):
        return location.split()[0]  # ì²« ë‹¨ì–´ë§Œ ë°˜í™˜
    
    # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if not location or location.strip() == "":
        return "Seoul"
    
    try:
        prompt = f"""
        ë‹¤ìŒ í•œêµ­ì–´ ì§€ì—­ëª…ì„ ë‚ ì”¨ APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜í•´ì¤˜.
        ë„ì‹œëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ë°˜í™˜í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ('ì„œìš¸ ê°•ë‚¨êµ¬' -> 'Seoul' ì²˜ëŸ¼).
        
        ì…ë ¥: {location}
        ì¶œë ¥ í˜•ì‹: ì˜ì–´ ë„ì‹œëª… (ì˜ˆ: Seoul, Busan, Incheon)
        """
        
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼
            max_tokens=20     # ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
        )
        
        city_name = res.choices[0].message.content.strip()
        
        # ê²°ê³¼ ê²€ì¦ (ì˜ì–´ë§Œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        if re.match(r'^[a-zA-Z\s-]+$', city_name):
            # ì—¬ëŸ¬ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ (ì˜ˆ: "Seoul City" -> "Seoul")
            return city_name.split()[0]
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì´ë©´ ê¸°ë³¸ê°’
            return "Seoul"
            
    except Exception as e:
        print(f"[ì§€ì—­ëª… ë³€í™˜ ì˜¤ë¥˜]: {e}")
        return "Seoul"  # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
