# gpt_service.py
# generat_marketing_idae í•¨ìˆ˜ ìœ ì§€
# langchain ì‚¬ìš© _get_or_create_chain, generate_conversation_response í•¨ìˆ˜ ì¶”ê°€

import os
import json
import re  # ì •ê·œì‹ ì‚¬ìš© ëª©ì 
import asyncio
from typing import Optional, Dict
from datetime import datetime
from enum import Enum
from openai import AsyncOpenAI
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from backend.app.core.schemas import DialogueGPTResponse_AD, DialogueGPTResponse_Profile, FinalContentSchema

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================== ëŒ€í™” ì˜ë„ ë¶„ë¥˜ ==================

class ConversationIntent(str, Enum):
    """ëŒ€í™” ì˜ë„ ë¶„ë¥˜"""
    PROFILE_BUILDING = "profile_building"  # ì²« ëŒ€í™”: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘ (ë¡œê·¸ì¸)
    GUEST_PROFILE = "guest_profile"  # ì²« ëŒ€í™”: ì¶•ì•½ í”„ë¡œí•„ ìˆ˜ì§‘ (ë¹„ë¡œê·¸ì¸)
    GUEST_AD_GENERATION = "guest_ad_generation"  # ë¹„ë¡œê·¸ì¸ ê´‘ê³  ìƒì„± (ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ í›„)
    INFO_UPDATE = "info_update"  # ì •ë³´ ì—…ë°ì´íŠ¸
    AD_GENERATION = "ad_generation"  # ê´‘ê³  ìƒì„±
    ANALYSIS = "analysis"  # ë¶„ì„/ì¡°ì–¸


def classify_user_intent(user_input: str, has_complete_profile: bool) -> ConversationIntent:
    """
    ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        has_complete_profile: í”„ë¡œí•„ì´ ì™„ì„±ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        
    Returns:
        ConversationIntent
    """
    
    # ì²« ëŒ€í™”ëŠ” ë¬´ì¡°ê±´ í”„ë¡œí•„ ìˆ˜ì§‘
    if not has_complete_profile:
        return ConversationIntent.PROFILE_BUILDING
    
    # ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­
    user_input_lower = user_input.lower()
    
    # ê´‘ê³  ìƒì„± ê´€ë ¨ í‚¤ì›Œë“œ
    ad_keywords = ['ê´‘ê³ ', 'ì´ë¯¸ì§€', 'í¬ìŠ¤í„°', 'í™ë³´', 'ë°°ë„ˆ', 'ë§Œë“¤ì–´', 'ìƒì„±', 'ë””ìì¸', 'ì•„ì´ë””ì–´']
    if any(keyword in user_input_lower for keyword in ad_keywords):
        return ConversationIntent.AD_GENERATION
    
    # ì •ë³´ ì—…ë°ì´íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ
    update_keywords = ['ìš”ì¦˜', 'ìš”ìƒˆ', 'ìµœê·¼', 'ì§€ê¸ˆ', 'ë°”ë€Œ', 'ë³€ê²½', 'ëŠ˜ì—ˆ', 'ì¤„ì—ˆ', 'ë§ì•„', 'ì ì–´', 'ë‹¬ë¼', 'ë‹¤ë¥´', 'ì¶”ê°€', 'ìƒˆë¡œ']
    if any(keyword in user_input_lower for keyword in update_keywords):
        return ConversationIntent.INFO_UPDATE
    
    # ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ
    analysis_keywords = ['ì™œ', 'ì´ìœ ', 'ë¶„ì„', 'ì–´ë–»ê²Œ', 'ì¶”ì²œ', 'ì¡°ì–¸', 'ë„ì›€']
    if any(keyword in user_input_lower for keyword in analysis_keywords):
        return ConversationIntent.ANALYSIS
    
    # ê¸°ë³¸ê°’: ê´‘ê³  ìƒì„±
    return ConversationIntent.AD_GENERATION

# langchain ë³€ìˆ˜ ì •ì˜
MAX_MEMORY_TURNS = 10
parser_ad = PydanticOutputParser(pydantic_object=DialogueGPTResponse_AD)
parser_profile = PydanticOutputParser(pydantic_object=DialogueGPTResponse_Profile)

# ì‚¬ìš©ìë³„ ëŒ€í™” ì„¸ì…˜ ì €ì¥ (user_id -> {chain, last_access})
CONVERSATION_MEMORIES: Dict[str, Dict] = {}

# ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì˜êµ¬ ì €ì¥ (ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ìœ ì§€)
USER_CONTEXTS: Dict[str, Dict] = {}

# ================== í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤ ==================

# 1ï¸âƒ£ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ìˆ˜ì§‘ í”„ë¡¬í”„íŠ¸ (ì²« ëŒ€í™” ì „ìš©)
PROFILE_BUILDING_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ê¸°ë³¸ ì •ë³´ (ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´) ===
ì—…ì¢…: {business_type}
ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}
ì˜ì—…ì‹œê°„: {business_hours}

=== í˜„ì¬ ìˆ˜ì§‘ëœ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì´ë²ˆì´ ì²« ëŒ€í™”ì´ë¯€ë¡œ, íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ…ì„ ìœ„í•´ ë‹¤ìŒ í•µì‹¬ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì§‘í•˜ì„¸ìš”:

1. **íƒ€ê²Ÿ ê³ ê°** (ì—°ë ¹ëŒ€, ì„±ë³„, ì§ì—…, íŠ¹ì„±)
   - ì˜ˆ: "ì£¼ë¡œ ì–´ë–¤ ê³ ê°ì¸µì´ ë§ì´ ë°©ë¬¸í•˜ì‹œë‚˜ìš”?"
   
2. **ì°¨ë³„í™” í¬ì¸íŠ¸** (ê²½ìŸì—…ì²´ ëŒ€ë¹„ ê°•ì )
   - ì˜ˆ: "ì£¼ë³€ {business_type}ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ íŠ¹ë³„í•œ ê°•ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
   
3. **ë¸Œëœë“œ ì»¨ì…‰** (ì¶”êµ¬í•˜ëŠ” ì´ë¯¸ì§€, ë¶„ìœ„ê¸°)
   - ì˜ˆ: "ì–´ë–¤ ë¶„ìœ„ê¸°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì¶”êµ¬í•˜ì‹œë‚˜ìš”?"
   
4. **ë§ˆì¼€íŒ… ëª©í‘œ** (ì‹ ê·œ ê³ ê° ìœ ì¹˜? ì¬ë°©ë¬¸ ì¦ëŒ€? ë§¤ì¶œ ì¦ê°€?)
   - ì˜ˆ: "í˜„ì¬ ê°€ì¥ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?"

=== ì¤‘ìš” ê·œì¹™ ===
- í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸í•˜ì„¸ìš” (ì—¬ëŸ¬ ì§ˆë¬¸ ë™ì‹œ ê¸ˆì§€)
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™” í†¤ ìœ ì§€
- ì‚¬ìš©ìê°€ ë‹µë³€í•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œë‚˜ ì„ íƒì§€ ì œê³µ
- ìœ„ 4ê°€ì§€ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ:
  * is_complete: true
  * last_ment: "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤" 
- ê¸°ë³¸ ì •ë³´(ì—…ì¢…, ìœ„ì¹˜, ë©”ë‰´ ë“±)ëŠ” ì ˆëŒ€ ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”
- ê°™ì€ ë‚´ìš©ì˜ ì§ˆë¬¸ì„ ì ˆëŒ€ 3ë²ˆ ì´ìƒ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 2ï¸âƒ£ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì¶•ì•½ í”„ë¡œí•„ ìˆ˜ì§‘ ë° ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸
GUEST_PROFILE_TEMPLATE = """
ë‹¹ì‹ ì€ ì¹œê·¼í•œ ë§ˆì¼€íŒ… ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

=== ëŒ€í™” ëª©í‘œ ===
ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìë¥¼ ìœ„í•œ ë¹ ë¥¸ ì •ë³´ ìˆ˜ì§‘ì„ ì§„í–‰í•©ë‹ˆë‹¤.
ë‹¤ìŒ 3ê°€ì§€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”:

1. **ì—…ì¢…ê³¼ ìœ„ì¹˜** (ì˜ˆ: ì„œìš¸ ê°•ë‚¨ ì¹´í˜, ë¶€ì‚° í•´ìš´ëŒ€ ìŒì‹ì )
2. **ì£¼ìš” ë©”ë‰´ë“¤** (ì˜ˆ: ì•„ë©”ë¦¬ì¹´ë…¸, ë¼ë–¼, ë””ì €íŠ¸)
3. **íƒ€ê²Ÿ ê³ ê°** (ì˜ˆ: 20ëŒ€ ì§ì¥ì¸, ëŒ€í•™ìƒ, 30ëŒ€ ì—¬ì„±)

=== ì§„í–‰ ë‹¨ê³„ ===
**1~2ë²ˆì§¸ ì§ˆë¬¸**: 
- í•œ ë²ˆì— í•˜ë‚˜ì”© ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸
- is_complete: false
- next_questionì— ë‹¤ìŒ ì§ˆë¬¸ ì‘ì„±

**3ë²ˆì§¸ ì§ˆë¬¸ ì‘ë‹µ ë°›ì€ í›„**:
- ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ
- is_complete: true
- final_contentì— ê´‘ê³  ìƒì„±:
  * idea: ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ (êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´)
  * caption: í™ë³´ ë¬¸êµ¬ (SNS ê²Œì‹œë¬¼ìš© ë§¤ë ¥ì ì¸ ë¬¸êµ¬)
  * hashtags: í•´ì‹œíƒœê·¸ ë¦¬ìŠ¤íŠ¸ (5~7ê°œ, ê´€ë ¨ì„± ë†’ì€ íƒœê·¸)
  * image_prompt: ì´ë¯¸ì§€ ìƒì„±ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ë¡œ ì‘ì„±, Stable Diffusionìš©)
  * bgm_prompt: MusicGenì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ í•œ ë¬¸ì¥.
      - ë°˜ë“œì‹œ í¬í•¨í•  ìš”ì†Œ:
        - ì¥ë¥´(genre): lo-fi hip hop, jazz, ambient ë“±
        - ë¶„ìœ„ê¸°(mood): cozy, energetic, dreamy, calm ë“±
        - í…œí¬(tempo): BPM(ì˜ˆ: 80-90 BPM) ë˜ëŠ” slow/medium/fast
        - ì•…ê¸°(instruments): piano, guitar, strings, soft drums ë“±
        - ì‚¬ìš© ë§¥ë½(context): small cafe, hair salon, casual restaurant ë“±
      - ì˜ˆì‹œ:
        "warm lo-fi hip hop instrumental, cozy and relaxed mood, 80-90 BPM, soft piano and light drums, background music for a small neighborhood cafe"


=== ì¤‘ìš” ê·œì¹™ ===
- 3ê°œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì‹œ is_complete: trueë¡œ ì„¤ì •
- ê´‘ê³ ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ë‹¤ìŒ ëŒ€í™”ì—ì„œ ìƒì„±)
- ê°„ê²°í•˜ê³  ë¹ ë¥´ê²Œ ì§„í–‰
- ì¹œê·¼í•œ í†¤ ìœ ì§€
- ê°™ì€ ì§ˆë¬¸ì€ ì ˆëŒ€ 3ë²ˆ ì´ìƒ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 2-2ï¸âƒ£ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸ (ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ í›„)
GUEST_AD_GENERATION_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ (ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´) ===
ì—…ì¢…: {business_type}
ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}
íƒ€ê²Ÿ ê³ ê°: {existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê´‘ê³ ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ **ì „ëµ í˜‘ì˜ í”„ë¡œì„¸ìŠ¤**ë¥¼ ë”°ë¥´ì„¸ìš”:

**ğŸ“‹ ë‹¨ê³„ 1: ê´‘ê³  ì „ëµ ì œì•ˆ**
ì‚¬ìš©ìê°€ ê´‘ê³ ë¥¼ ìš”ì²­í•˜ë©´, ì¦‰ì‹œ ìƒì„±í•˜ì§€ ë§ê³  ë¨¼ì € êµ¬ì²´ì ì¸ ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”:

1. **ë©”ì¸ ë©”ì‹œì§€**: í•µì‹¬ ë¬¸êµ¬ (ì˜ˆ: "ë”°ëœ»í•œ í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ê±´ê°•í•œ ë¹µê³¼ í•¨ê»˜")
2. **íƒ€ê²Ÿ ê³ ê°**: ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ? (ìœ„ íƒ€ê²Ÿ ê³ ê° ì •ë³´ í™œìš©)
3. **ë¹„ì£¼ì–¼ ì»¨ì…‰**: ì–´ë–¤ ëŠë‚Œ? (ì˜ˆ: ì•„ëŠ‘í•œ, íŠ¸ë Œë””í•œ, ê³ ê¸‰ìŠ¤ëŸ¬ìš´)
4. **ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼**: êµ¬ì²´ì ì¸ ë¹„ì£¼ì–¼ ë°©í–¥
5. **ì£¼ìš” ìš”ì†Œ**: í¬í•¨í•  ë‚´ìš© (ì œí’ˆ, ì´ë²¤íŠ¸, í• ì¸ ë“±)

ì „ëµ ì œì•ˆ í›„ ë°˜ë“œì‹œ:
- "ì´ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í• ê¹Œìš”?"
- "ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
- is_complete: falseë¡œ ì„¤ì •

**ğŸ”„ ë‹¨ê³„ 2: í”¼ë“œë°± ë°˜ì˜**
ì‚¬ìš©ìê°€ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´:
- í”¼ë“œë°±ì„ ë°˜ì˜í•œ **ìˆ˜ì •ëœ ì „ëµ**ì„ ë‹¤ì‹œ ì œì‹œ
- "ì´ë ‡ê²Œ ìˆ˜ì •í–ˆëŠ”ë°, ê´œì°®ìœ¼ì‹ ê°€ìš”?"
- ì—¬ì „íˆ is_complete: false

**âœ… ë‹¨ê³„ 3: ìµœì¢… ìƒì„±**
ì‚¬ìš©ìê°€ **ëª…í™•í•˜ê²Œ ë™ì˜**í•  ë•Œë§Œ ìµœì¢… ê´‘ê³ ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ë™ì˜ í‘œí˜„ ì˜ˆì‹œ:**
- "ì¢‹ì•„ìš”", "ê´œì°®ì•„ìš”", "ì˜¤ì¼€ì´", "ê·¸ë ‡ê²Œ í•´ì£¼ì„¸ìš”"
- "ë§Œë“¤ì–´ì£¼ì„¸ìš”", "ìƒì„±í•´ì£¼ì„¸ìš”", "ì§„í–‰í•´ì£¼ì„¸ìš”"
- "ë„¤", "ì‘", "ì˜ˆ", "ê·¸ë˜"

ë™ì˜ í™•ì¸ í›„:
- is_complete: true
- final_contentì— ìµœì¢… ê´‘ê³  ìƒì„± (idea, caption, hashtags, image_prompt)

=== ì¤‘ìš” ê·œì¹™ ===
1. **ì ˆëŒ€ ë°”ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”**: ì‚¬ìš©ì ë™ì˜ ì—†ì´ is_complete=true ê¸ˆì§€
2. **ì „ëµë§Œ ì œì•ˆ**: ë™ì˜ ì „ê¹Œì§€ëŠ” í•­ìƒ next_questionì— ì „ëµ ì œì•ˆ
3. **ëª…í™•í•œ ë™ì˜ ëŒ€ê¸°**: ì• ë§¤í•œ ë°˜ì‘ì—ëŠ” ë‹¤ì‹œ í™•ì¸
4. **ë¬´í•œ ìˆ˜ì • ê°€ëŠ¥**: ì‚¬ìš©ìê°€ ë§Œì¡±í•  ë•Œê¹Œì§€ ì „ëµ ì¡°ì •
5. **ìˆ˜ì§‘ëœ ì •ë³´ í™œìš©**: ìœ„ ì‚¬ì—…ì ì •ë³´ë¥¼ ì ê·¹ ë°˜ì˜

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 3ï¸âƒ£ ì •ë³´ ì—…ë°ì´íŠ¸ í”„ë¡¬í”„íŠ¸
INFO_UPDATE_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== í˜„ì¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.

=== ì¤‘ìš” ê·œì¹™ ===
- ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ ì‹œ:
  * is_complete: true
  * last_ment: "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤" 

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 3ï¸âƒ£ ê´‘ê³  ìƒì„± í”„ë¡¬í”„íŠ¸ (2ë‹¨ê³„: ì „ëµ í˜‘ì˜ â†’ ìµœì¢… ìƒì„±)
AD_GENERATION_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê´‘ê³ ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ **ì „ëµ í˜‘ì˜ í”„ë¡œì„¸ìŠ¤**ë¥¼ ë”°ë¥´ì„¸ìš”:

**ğŸ“‹ ë‹¨ê³„ 1: ê´‘ê³  ì „ëµ ì œì•ˆ**
ì‚¬ìš©ìê°€ ê´‘ê³ ë¥¼ ìš”ì²­í•˜ë©´, ì¦‰ì‹œ ìƒì„±í•˜ì§€ ë§ê³  ë¨¼ì € êµ¬ì²´ì ì¸ ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”:

1. **ë©”ì¸ ë©”ì‹œì§€**: í•µì‹¬ ë¬¸êµ¬ (ì˜ˆ: "ë”°ëœ»í•œ í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ê±´ê°•í•œ ë¹µê³¼ í•¨ê»˜")
2. **íƒ€ê²Ÿ ê³ ê°**: ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ? (ê¸°ì¡´ ì „ëµ ì •ë³´ í™œìš©)
3. **ë¹„ì£¼ì–¼ ì»¨ì…‰**: ì–´ë–¤ ëŠë‚Œ? (ì˜ˆ: ì•„ëŠ‘í•œ, íŠ¸ë Œë””í•œ, ê³ ê¸‰ìŠ¤ëŸ¬ìš´)
4. **ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼**: êµ¬ì²´ì ì¸ ë¹„ì£¼ì–¼ ë°©í–¥
5. **ì£¼ìš” ìš”ì†Œ**: í¬í•¨í•  ë‚´ìš© (ì œí’ˆ, ì´ë²¤íŠ¸, í• ì¸ ë“±)

ì „ëµ ì œì•ˆ í›„ ë°˜ë“œì‹œ:
- "ì´ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í• ê¹Œìš”?"
- "ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
- is_complete: falseë¡œ ì„¤ì •

**ğŸ”„ ë‹¨ê³„ 2: í”¼ë“œë°± ë°˜ì˜**
ì‚¬ìš©ìê°€ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´:
- í”¼ë“œë°±ì„ ë°˜ì˜í•œ **ìˆ˜ì •ëœ ì „ëµ**ì„ ë‹¤ì‹œ ì œì‹œ
- "ì´ë ‡ê²Œ ìˆ˜ì •í–ˆëŠ”ë°, ê´œì°®ìœ¼ì‹ ê°€ìš”?"
- ì—¬ì „íˆ is_complete: false

----------------------------------------
âœ… ë‹¨ê³„ 3: ìµœì¢… ìƒì„±
----------------------------------------
ì‚¬ìš©ìê°€ **ì „ëµ ë™ì˜ + ìƒì„± ë°©ì‹ ì„ íƒ** ë‘ ê°€ì§€ ëª¨ë‘ ì™„ë£Œí•œ ë’¤ ìµœì¢… ê´‘ê³ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**ë™ì˜ í‘œí˜„ ì˜ˆì‹œ**
- "ì¢‹ì•„ìš”", "ê´œì°®ì•„ìš”", "ê·¸ë ‡ê²Œ í•´ì£¼ì„¸ìš”"
- "ë§Œë“¤ì–´ì£¼ì„¸ìš”", "ìƒì„±í•´ì£¼ì„¸ìš”", "ì§„í–‰í•´ì£¼ì„¸ìš”"

ë™ì˜ í™•ì¸ + ìƒì„± ë°©ì‹ ì„ íƒ ì™„ë£Œ ì‹œ:
- is_complete: true
- final_contentì— ì•„ë˜ í•­ëª© ëª¨ë‘ í¬í•¨:
  * idea: ë§ˆì¼€íŒ… ì•„ì´ë””ì–´
  * caption: í™ë³´ ë¬¸êµ¬
  * hashtags: SNS í•´ì‹œíƒœê·¸ ë¦¬ìŠ¤íŠ¸
  * image_prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
  * bgm_prompt: MusicGen í”„ë¡¬í”„íŠ¸


=== ì¤‘ìš” ê·œì¹™ ===
1. **ì ˆëŒ€ ë°”ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”**: ì‚¬ìš©ì ë™ì˜ ì—†ì´ is_complete=true ê¸ˆì§€
2. **ì „ëµë§Œ ì œì•ˆ**: ë™ì˜ ì „ê¹Œì§€ëŠ” í•­ìƒ next_questionì— ì „ëµ ì œì•ˆ
3. **ëª…í™•í•œ ë™ì˜ ëŒ€ê¸°**: ì• ë§¤í•œ ë°˜ì‘ì—ëŠ” ë‹¤ì‹œ í™•ì¸
4. **ë¬´í•œ ìˆ˜ì • ê°€ëŠ¥**: ì‚¬ìš©ìê°€ ë§Œì¡±í•  ë•Œê¹Œì§€ ì „ëµ ì¡°ì •
5. **ê¸°ì¡´ ì •ë³´ í™œìš©**: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì ê·¹ ë°˜ì˜
6. **í•œê¸€, ì˜ì–´ êµ¬ë¶„**: idea, caption, hashtagsëŠ” í•œê¸€ë¡œ image_prompt, bgm_promptëŠ” ì˜ì–´ë¡œ ì‘ì„±

=== ì¶œë ¥ í˜•ì‹ ===
ìµœì¢… ê´‘ê³ ë¥¼ ìƒì„±í•  ë•Œ(final_contentì— ë‹´ì„ ë•Œ) í•„ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±:

- idea: ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ (êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´)
- caption: í™ë³´ ë¬¸êµ¬ (SNS ê²Œì‹œë¬¼ìš© ë§¤ë ¥ì ì¸ ë¬¸êµ¬)
- hashtags: í•´ì‹œíƒœê·¸ ë¦¬ìŠ¤íŠ¸ (5~7ê°œ, ê´€ë ¨ì„± ë†’ì€ íƒœê·¸)
- image_prompt: ì´ë¯¸ì§€ ìƒì„±ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ë¡œ ì‘ì„±, Stable Diffusionìš©)
- bgm_prompt

bgm_promptëŠ” MusicGenì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë¬¸ì¥ì´ì–´ì•¼ í•˜ë©° ì•„ë˜ ìš”ì†Œë¥¼ ë°˜ë“œì‹œ í¬í•¨:
    - ì¥ë¥´(genre): lo-fi hip hop, jazz, ambient ë“±
    - ë¶„ìœ„ê¸°(mood): cozy, energetic, dreamy, calm ë“±
    - í…œí¬(tempo): BPM(ì˜ˆ: 80-90 BPM) ë˜ëŠ” slow/medium/fast
    - ì•…ê¸°(instruments): piano, guitar, strings, soft drums ë“±
    - ì‚¬ìš© ë§¥ë½(context): small cafe, hair salon, casual restaurant ë“±
- ì˜ˆì‹œ:
    "warm lo-fi hip hop instrumental, cozy and relaxed mood, 80-90 BPM, soft piano and light drums, background music for a small neighborhood cafe"


=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""

# 4ï¸âƒ£ ë¶„ì„/ì¡°ì–¸ í”„ë¡¬í”„íŠ¸ (í‹€ë§Œ)
ANALYSIS_TEMPLATE = """
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ì „ë‹´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ì‚¬ì—…ì ì •ë³´ ===
ì—…ì¢…: {business_type} | ìœ„ì¹˜: {location}
ì£¼ë ¥ ìƒí’ˆ: {menu_items}

=== ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ===
{existing_strategy}

=== ëŒ€í™” ëª©í‘œ ===
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
(ì´ í”„ë¡¬í”„íŠ¸ëŠ” í–¥í›„ êµ¬í˜„ ì˜ˆì •)

=== í˜„ì¬ ëŒ€í™” ===
{history}

ì‚¬ìš©ì: {input}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{format_instructions}
"""


def _safe_json_from_text(text: str) -> dict:
    """
    ëª¨ë¸ì´ ```json ... ``` ê°™ì€ ì½”ë“œë¸”ë¡ì„ ì„ì–´ ë³´ë‚´ê±°ë‚˜
    ìì—°ì–´ê°€ í•¨ê»˜ í¬í•¨ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•œ ì•ˆì „ íŒŒì„œ ì—­í• 
    """
    # 1) ì½”ë“œíœìŠ¤ ì œê±° ì‹œë„ ì—­í• 
    cleaned = text.replace("```json", "").replace("```", "").strip()

    # 2) ì •ê·œì‹ìœ¼ë¡œ ê°€ì¥ ë°”ê¹¥ { ... } ê°ì²´ë§Œ ì¶”ì¶œ ì‹œë„ ì—­í• 
    #    - ì¤‘ê°„ì— ì„¤ëª… ë¬¸ì¥ì´ ìˆì–´ë„ ì²« JSON ì˜¤ë¸Œì íŠ¸ë§Œ ë½‘ê¸° ëª©ì 
    match = re.search(r"\{[\s\S]*\}", cleaned)  # ì¤„ë°”ê¿ˆ í¬í•¨ íƒìƒ‰ ì—­í• 
    if match:
        cleaned = match.group(0)

    # 3) json.loads ì‹œë„ ë° ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ëª©ì  í…ìŠ¤íŠ¸ í•¨ê»˜ ì˜ˆì™¸ ë°˜í™˜ ì—­í• 
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        raise ValueError(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë¬¸: {text[:300]}...")  # ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€ ëª©ì 

        
       

# ================== Multi-turn langchain ëŒ€í™” ê´€ë¦¬ í•¨ìˆ˜ ==================

def _check_profile_completeness(context: dict) -> bool:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ê°€ ì¶©ë¶„íˆ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not context or not context.get("memory"):
        return False
    
    memory = context["memory"]
    if not memory or not hasattr(memory, 'marketing_strategy'):
        return False
    
    strategy = memory.marketing_strategy
    if not strategy:
        return False
    
    # í•„ìˆ˜ í•„ë“œ ì²´í¬
    required_fields = [
        strategy.get("target_audience"),
        strategy.get("competitive_advantage"),
        strategy.get("brand_concept")
    ]
    
    return all(field is not None for field in required_fields)


def _format_strategy_info(memory) -> str:
    """ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not memory or not hasattr(memory, 'marketing_strategy') or not memory.marketing_strategy:
        return "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"
    
    strategy = memory.marketing_strategy
    lines = []
    
    if strategy.get("target_audience"):
        ta = strategy["target_audience"]
        lines.append(f"- íƒ€ê²Ÿ ê³ ê°: {ta}")
    
    if strategy.get("competitive_advantage"):
        lines.append(f"- ì°¨ë³„í™” í¬ì¸íŠ¸: {strategy['competitive_advantage']}")
    
    if strategy.get("brand_concept"):
        lines.append(f"- ë¸Œëœë“œ ì»¨ì…‰: {strategy['brand_concept']}")
    
    if strategy.get("marketing_goals"):
        lines.append(f"- ë§ˆì¼€íŒ… ëª©í‘œ: {strategy['marketing_goals']}")
    
    return "\n".join(lines) if lines else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ ì—†ìŒ"


async def generate_conversation_response(
    user_input: str,
    session_key: str,
    is_guest: bool = False,
    user_context: dict = None
) -> DialogueGPTResponse_AD | DialogueGPTResponse_Profile:
    """
    [ë¹„ë™ê¸° ë²„ì „] langchain ì‚¬ìš©í•´ì„œ multi-turn ëŒ€í™” ì‘ë‹µ ìƒì„±
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        session_key: ì„¸ì…˜ í‚¤ (user-{id} or guest-{uuid})
        is_guest: ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì—¬ë¶€
        user_context: ì‚¬ìš©ì í”„ë¡œí•„ ë° ì¥ê¸° ë©”ëª¨ë¦¬ (ìƒˆ ì„¸ì…˜ì—ë§Œ ì œê³µ)
    
    Returns:
        DialogueGPTResponse: ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ìµœì¢… ì½˜í…ì¸ 
    """
    try:
        # ì„¸ì…˜ ì¬ì‚¬ìš© ë˜ëŠ” ìƒˆ ì„¸ì…˜ ìƒì„±
        if session_key in CONVERSATION_MEMORIES:
            print(f"â™»ï¸  ê¸°ì¡´ ëŒ€í™” ì„¸ì…˜ ì¬ì‚¬ìš©: {session_key}")
            session = CONVERSATION_MEMORIES[session_key]
            memory_obj = session["memory"]
            chain = session["chain"]
            intent = session["intent"]
            parser = session["parser"]
                
        else:
            print(f"âœ… ìƒˆ ëŒ€í™” ì„¸ì…˜ ìƒì„±: {session_key}")
            
            # ì¸í…íŠ¸ ê²°ì •
            if is_guest:
                # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: user_context ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨
                if user_context and user_context.get("business_type") and user_context.get("business_type") != "ë¯¸í™•ì¸":
                    # ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ â†’ ê´‘ê³  ìƒì„± ëª¨ë“œ
                    intent = ConversationIntent.GUEST_AD_GENERATION
                    print(f"ğŸ¯ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì •ë³´ ìˆìŒ â†’ ê´‘ê³  ìƒì„± ëª¨ë“œ")
                else:
                    # ì •ë³´ ìˆ˜ì§‘ í•„ìš” â†’ í”„ë¡œí•„ ìˆ˜ì§‘ ëª¨ë“œ
                    intent = ConversationIntent.GUEST_PROFILE
                    print(f"ğŸ†• ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì •ë³´ ì—†ìŒ â†’ í”„ë¡œí•„ ìˆ˜ì§‘ ëª¨ë“œ")
            elif user_context:
                # ë¡œê·¸ì¸ ì‚¬ìš©ì: ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ì™„ì„± ì—¬ë¶€ ì²´í¬
                has_complete_profile = _check_profile_completeness(user_context)
                if has_complete_profile:
                    # í”„ë¡œí•„ ì™„ì„± â†’ ê´‘ê³  ìƒì„± ë˜ëŠ” ì •ë³´ ì—…ë°ì´íŠ¸
                    intent = classify_user_intent(user_input, has_complete_profile=True)
                else:
                    # í”„ë¡œí•„ ë¯¸ì™„ì„± â†’ ìƒì„¸ í”„ë¡œí•„ ìˆ˜ì§‘
                    intent = ConversationIntent.PROFILE_BUILDING
            else:
                # user_context ì—†ìŒ â†’ í”„ë¡œí•„ ìˆ˜ì§‘
                intent = ConversationIntent.PROFILE_BUILDING
            
            print(f"ğŸ¯ ê°ì§€ëœ ì˜ë„: {intent.value}")
            
            # í”„ë¡¬í”„íŠ¸ ë° íŒŒì„œ ì„ íƒ
            if intent == ConversationIntent.GUEST_PROFILE:
                template = GUEST_PROFILE_TEMPLATE
                parser = parser_profile  # ë¹„ë¡œê·¸ì¸ ì²« ëŒ€í™”ëŠ” ì •ë³´ ìˆ˜ì§‘ ìŠ¤í‚¤ë§ˆ
            elif intent == ConversationIntent.GUEST_AD_GENERATION:
                template = GUEST_AD_GENERATION_TEMPLATE
                parser = parser_ad
            elif intent == ConversationIntent.PROFILE_BUILDING:
                template = PROFILE_BUILDING_TEMPLATE
                parser = parser_profile
            elif intent == ConversationIntent.INFO_UPDATE:
                template = INFO_UPDATE_TEMPLATE
                parser = parser_profile
            elif intent == ConversationIntent.AD_GENERATION:
                template = AD_GENERATION_TEMPLATE
                parser = parser_ad
            else:
                template = PROFILE_BUILDING_TEMPLATE
                parser = parser_profile
            
            # ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ í¬ë§·íŒ…
            strategy_text = _format_strategy_info(user_context.get("memory") if user_context else None)
            
            # LangChain ì„¤ì •
            llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.7,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )
            
            memory_obj = ConversationBufferWindowMemory(
                k=MAX_MEMORY_TURNS,
                memory_key="history",
                return_messages=True
            )
            
            prompt = PromptTemplate(
                template=template,
                input_variables=["input"],
                partial_variables={
                    "format_instructions": parser.get_format_instructions(),
                    "business_type": user_context.get("business_type", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "location": user_context.get("location", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "menu_items": user_context.get("menu_items", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "business_hours": user_context.get("business_hours", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                    "existing_strategy": strategy_text
                },
            )
            
            chain = ConversationChain(
                llm=llm,
                prompt=prompt,
                memory=memory_obj,
                verbose=False
            )
            
            # ì„¸ì…˜ ì €ì¥
            CONVERSATION_MEMORIES[session_key] = {
                "memory": memory_obj,
                "chain": chain,
                "intent": intent,
                "parser": parser,
                "user_context": user_context  # ë¡œê·¸ì¸/ë¹„ë¡œê·¸ì¸ ëª¨ë‘ ë™ì¼í•˜ê²Œ ê´€ë¦¬
            }
        
        # langchain ì‹¤í–‰(ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬ & í”„ë¡¬í”„íŠ¸ ì£¼ì…) - asyncio.to_thread ì‚¬ìš©
        raw_response = await asyncio.to_thread(
            lambda: chain.invoke(input=user_input)['response'].strip()
        )
        
        # ì˜ë„ ê°€ì ¸ì˜¤ê¸°
        session = CONVERSATION_MEMORIES.get(session_key)
        intent = session.get("intent") if session else ConversationIntent.AD_GENERATION
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (ì´ë¯¸ parserê°€ ì˜¬ë°”ë¥¸ íƒ€ì…ìœ¼ë¡œ íŒŒì‹±í•¨)
        data = _safe_json_from_text(raw_response)
        
        if intent in [ConversationIntent.AD_GENERATION, ConversationIntent.GUEST_AD_GENERATION]:
            # ê´‘ê³  ìƒì„± ëª¨ë“œ (ë¡œê·¸ì¸ AD_GENERATION + ë¹„ë¡œê·¸ì¸ GUEST_AD_GENERATION)
            data["type"] = "ad"  # type í•„ë“œ ê°•ì œ ì£¼ì…
            response = DialogueGPTResponse_AD(**data)
            
            # ----------------------------------------
            # bgm_prompt ìµœì†Œ ê²€ì¦ + ë³´ì •
            # ----------------------------------------
            if response.final_content:
                bgm_prompt = (response.final_content.bgm_prompt or "").strip()

                # 1) ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ êµì²´
                if not bgm_prompt:
                    bgm_prompt = (
                        "warm lo-fi hip hop instrumental, cozy and relaxed mood, "
                        "80-90 BPM, soft piano and light drums, "
                        "background music for a small neighborhood cafe"
                    )
                else:
                    # 2) ë„ˆë¬´ ì§§ìœ¼ë©´ (ë‹¨ì–´ 5ê°œ ë¯¸ë§Œ) ê¸°ë³¸ê°’ìœ¼ë¡œ êµì²´
                    if len(bgm_prompt.split()) < 5:
                        bgm_prompt = (
                            "warm lo-fi hip hop instrumental, cozy and relaxed mood, "
                            "80-90 BPM, soft piano and light drums, "
                            "background music for a small neighborhood cafe"
                        )

                # 3) pydantic ê°ì²´ ì—…ë°ì´íŠ¸
                updated_final_content = response.final_content.model_copy(
                    update={"bgm_prompt": bgm_prompt}
                )
                response = response.model_copy(update={"final_content": updated_final_content})
                           
        else:
            # PROFILE_BUILDING, INFO_UPDATE, ANALYSIS, GUEST_PROFILE
            data["type"] = "profile"  # type í•„ë“œ ê°•ì œ ì£¼ì…
            # GPTê°€ last_mentë¥¼ ì•ˆ ë³´ë‚´ë©´ ê°•ì œ ì£¼ì…
            if data.get("is_complete") and not data.get("last_ment"):
                data["last_ment"] = "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤"
            response = DialogueGPTResponse_Profile(**data)
        
        # ëŒ€í™” ì™„ë£Œ ì‹œ: ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ + Vision í†µí•© (ì„¸ì…˜ ì‚­ì œëŠ” gpt.pyì—ì„œ ì²˜ë¦¬)
        if response.is_complete and session_key in CONVERSATION_MEMORIES:
            # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì²« ëŒ€í™” ì™„ë£Œ: ì •ë³´ ì €ì¥
            if is_guest and intent == ConversationIntent.GUEST_PROFILE:
                print("âœ… ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ì •ë³´ ì¶”ì¶œ
                messages = memory_obj.chat_memory.messages
                
                # ê°„ë‹¨í•œ ì •ë³´ ì¶”ì¶œ: ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©ì—ì„œ ì¶”ì¶œ
                collected_info = {
                    "business_type": "ë¯¸í™•ì¸",
                    "location": "ë¯¸í™•ì¸",
                    "menu_items": "ë¯¸í™•ì¸",
                    "target_audience": "ë¯¸í™•ì¸"
                }
                
                # ì‚¬ìš©ì ì‘ë‹µë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥ (ê°„ë‹¨í•œ ë°©ì‹)
                user_responses = [msg.content for msg in messages if msg.type == "human"]
                if len(user_responses) >= 1:
                    collected_info["business_type"] = user_responses[0] if len(user_responses) > 0 else "ë¯¸í™•ì¸"
                if len(user_responses) >= 2:
                    collected_info["menu_items"] = user_responses[1] if len(user_responses) > 1 else "ë¯¸í™•ì¸"
                if len(user_responses) >= 3:
                    collected_info["target_audience"] = user_responses[2] if len(user_responses) > 2 else "ë¯¸í™•ì¸"
                
                # locationì€ business_typeì—ì„œ ì¶”ì¶œ ì‹œë„ (ì˜ˆ: "ì„œìš¸ ê°•ë‚¨ ì¹´í˜" â†’ location: "ì„œìš¸ ê°•ë‚¨")
                if collected_info["business_type"] != "ë¯¸í™•ì¸":
                    parts = collected_info["business_type"].split()
                    if len(parts) >= 2:
                        collected_info["location"] = " ".join(parts[:-1])  # ë§ˆì§€ë§‰ ë‹¨ì–´(ì—…ì¢…) ì œì™¸
                
                # USER_CONTEXTSì— ì˜êµ¬ ì €ì¥ (ì„¸ì…˜ ì‚­ì œë˜ì–´ë„ ìœ ì§€)
                USER_CONTEXTS[session_key] = collected_info
                print(f"ğŸ’¾ ìˆ˜ì§‘ëœ ì •ë³´ ì €ì¥ (USER_CONTEXTS): {collected_info}")
                print("â¡ï¸  ë‹¤ìŒ ëŒ€í™”ëŠ” GUEST_AD_GENERATION ëª¨ë“œë¡œ ì‹œì‘ë©ë‹ˆë‹¤")
            
            # ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ
            messages = memory_obj.chat_memory.messages
            conversation_history = [
                {
                    "role": "user" if msg.type == "human" else "assistant",
                    "content": msg.content
                }
                for msg in messages
            ]
            response.conversation_history = conversation_history
            print(f"ğŸ“ ëŒ€í™” ê¸°ë¡ ì¶”ì¶œ ì™„ë£Œ: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
            
            # Vision í†µí•©: ê´‘ê³  ìƒì„± ì™„ë£Œ + ì œí’ˆ ì´ë¯¸ì§€ ì¡´ì¬ ì‹œ
            if (
                intent in [ConversationIntent.AD_GENERATION, ConversationIntent.GUEST_AD_GENERATION]
                and response.final_content
                and "product_image" in CONVERSATION_MEMORIES[session_key]
                and CONVERSATION_MEMORIES[session_key]["product_image"]
            ):
                try:
                    print("ğŸ” Vision ë¶„ì„ ì‹œì‘...")
                    
                    # 1. ì „ëµ ì œì•ˆ ì¶”ì¶œ
                    strategy_proposal = extract_last_strategy_proposal(conversation_history)
                    
                    if strategy_proposal:
                        print(f"âœ… ì „ëµ ì œì•ˆ ì¶”ì¶œ ì„±ê³µ: {strategy_proposal[:100]}...")
                        
                        # 2. Visionìœ¼ë¡œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
                        product_image_base64 = CONVERSATION_MEMORIES[session_key]["product_image"]
                        business_info = {
                            "business_type": user_context.get("business_type", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                            "location": user_context.get("location", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸",
                            "menu_items": user_context.get("menu_items", "ë¯¸í™•ì¸") if user_context else "ë¯¸í™•ì¸"
                        }
                        
                        enhanced_prompt = await generate_detailed_image_prompt_with_vision(
                            strategy_proposal=strategy_proposal,
                            product_image_base64=product_image_base64,
                            business_info=business_info
                        )
                        
                        # 3. image_prompt êµì²´
                        if enhanced_prompt:
                            # Pydantic ëª¨ë¸ ì—…ë°ì´íŠ¸
                            updated_final_content = response.final_content.model_copy(
                                update={"image_prompt": enhanced_prompt}
                            )
                            response = response.model_copy(
                                update={"final_content": updated_final_content}
                            )
                            print("âœ… Vision í”„ë¡¬í”„íŠ¸ ì ìš© ì™„ë£Œ")
                    else:
                        print("âš ï¸  ì „ëµ ì œì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (Vision ìŠ¤í‚µ)")
                        
                except Exception as e:
                    print(f"âŒ Vision í†µí•© ì‹¤íŒ¨ (ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìœ ì§€): {e}")
        
        return response

    except Exception as e:
        raise ValueError(f"LangChain ëŒ€í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")



      
# ë‹¨ì¼ ì½˜í…ì¸  ìƒì„±
async def generate_marketing_idea(prompt_text: str, context=None) -> dict:
    """
    [ë¹„ë™ê¸° ë²„ì „] ë‹¨ì¼ í„´ì—ì„œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ìƒì„±í•˜ëŠ” ì—­í• 
    - ë§ˆì¼€íŒ… ì•„ì´ë””ì–´/ìº¡ì…˜/í•´ì‹œíƒœê·¸/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—­í• 
    - ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ JSONìœ¼ë¡œ ê°•ì œ ë° ì•ˆì „ íŒŒì‹± ì—­í• 
    """
    #( ê¸°ì¡´ generate_marketing_idea í•¨ìˆ˜ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    
    # 1) ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ êµ¬ì„± ì—­í• 
    system = (
        "ë„ˆëŠ” ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ ì—­í• . "
        "í˜„ì¬ ë‚ ì§œì™€ ê³„ì ˆ ë° ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ì•¼ í•¨. "
        "ì˜ˆ: 11ì›”ì´ë©´ ê°€ì„/ê²¨ìš¸ ì´ë²¤íŠ¸, 5ì›”ì´ë©´ ë´„ ì´ë²¤íŠ¸ë¥¼ ì œì•ˆ. "
        "í•­ìƒ JSON ì˜¤ë¸Œì íŠ¸ë§Œ ì¶œë ¥. ì½”ë“œë¸”ë¡/ì„¤ëª…/ì¶”ê°€ ë¬¸ì¥ ê¸ˆì§€."
        "bgm_promptëŠ” MusicGen ê°™ì€ ìŒì•… ìƒì„± ëª¨ë¸ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•´ì•¼ í•¨. "
        "bgm_promptì—ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ ìš”ì†Œê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•¨: "
        "ì¥ë¥´(genre), ë¶„ìœ„ê¸°(mood), í…œí¬(tempo ë˜ëŠ” BPM), ì£¼ìš” ì•…ê¸°(instruments), "
        "ì‚¬ìš© ë§¥ë½(context: ì˜ˆë¥¼ ë“¤ì–´ small cafe, hair salon, casual restaurant ë“±)."       
    )

    # 2) ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì—­í• 
    user = f"""
    ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œìƒê³µì¸ì„ ìœ„í•œ í™ë³´ ì½˜í…ì¸ ë¥¼ JSON í˜•íƒœë¡œ ìƒì„±í•´ì¤˜.

    ì…ë ¥:
    - ì‚¬ìš©ì ìš”ì²­: {prompt_text}
    - ë§¥ë½ ì •ë³´: {context or 'ë‚ ì”¨, ì—…ì¢…, ë¶„ìœ„ê¸° ë“±'}

    ì¶œë ¥(JSON ì˜¤ë¸Œì íŠ¸ë§Œ, ì¶”ê°€ í…ìŠ¤íŠ¸/ì½”ë“œë¸”ë¡ ê¸ˆì§€):
    ì¶œë ¥(JSON í˜•ì‹ìœ¼ë¡œë§Œ, ``json ë¸”ë¡ ì—†ì´):
    {{
     "idea": "ì§§ì€ ì´ë²¤íŠ¸ ì•„ì´ë””ì–´ ë¬¸ì¥",
      "caption": "í™ë³´ìš© ë¬¸êµ¬(ì§§ê³  ê°ì„±ì ì¸ ë¬¸ì¥)",
      "hashtags": ["#ì˜ˆì‹œ", "#í™ë³´", "#ì§€ì—­ëª…"],
      "image_prompt": "Stable Diffusionìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸",
      "bgm_prompt": "warm lo-fi hip hop instrumental, cozy and relaxed mood, 80-90 BPM, soft piano and light drums, background music for a small neighborhood cafe"
    }}
    """.strip()

    try:
        # 3) Chat Completions í˜¸ì¶œ ì—­í• 
        #    - ê°€ëŠ¥ ëª¨ë¸ì˜ ê²½ìš° JSON ê°•ì œ í¬ë§· ì§€ì • ì—­í• 
        res = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.7,
            # ì§€ì›ë˜ëŠ” ëª¨ë¸ì¸ ê²½ìš°ë§Œ ë™ì‘. ë¯¸ì§€ì›ì´ë©´ ì œê±° í•„ìš”ì„±.
            response_format={"type": "json_object"},
        )

        # 4) ì½˜í…ì¸  ì¶”ì¶œ ë° ë„/ì¸ë±ìŠ¤ ë³´í˜¸ ì—­í• 
        if not res.choices or not res.choices[0].message or not res.choices[0].message.content:
            raise ValueError("ëª¨ë¸ ì‘ë‹µ ë¹„ì •ìƒ: content ì—†ìŒ")

        content = res.choices[0].message.content.strip()
        # 5) ì•ˆì „ íŒŒì‹± ìˆ˜í–‰ ì—­í• 
        data = _safe_json_from_text(content)


        # 6) ìŠ¤í‚¤ë§ˆ ë³´ì •(íƒ€ì…/í•„ë“œ ê¸°ë³¸ê°’ ì±„ìš°ê¸°) ì—­í• 
        idea = data.get("idea", "").strip()
        caption = data.get("caption", "").strip()
        hashtags = data.get("hashtags", [])
        image_prompt = data.get("image_prompt", "").strip()
        bgm_prompt = data.get("bgm_prompt", "").strip() # ìƒˆë¡œ ì¶”ê°€ : bgm í”„ë¡¬í”„íŠ¸

        if not isinstance(hashtags, list):
            hashtags = []
        # 7) ìµœì†Œ í•„ìˆ˜ê°’ ì ê²€ ì—­í• 
        if not image_prompt:
            # image_prompt ëˆ„ë½ ì‹œ ìº¡ì…˜/ì•„ì´ë””ì–´ ê¸°ë°˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ë³´ì • ì—­í• 
            fallback = "clean promotional poster, high quality, modern typography"
            image_prompt = f"{caption or idea}, {fallback}"
        if not bgm_prompt:
            bgm_prompt = (
                "warm lo-fi hip hop instrumental, cozy and relaxed mood, "
                "80-90 BPM, soft piano and light drums, "
                "background music for a small neighborhood cafe"
            )
        else:
            if len(bgm_prompt.split()) < 5:
                bgm_prompt = (
                    "warm lo-fi hip hop instrumental, cozy and relaxed mood, "
                    "80-90 BPM, soft piano and light drums, "
                    "background music for a small neighborhood cafe"          
                )

        return {
            "idea": idea,
            "caption": caption,
            "hashtags": hashtags,
            "image_prompt": image_prompt,
            "bgm_prompt": bgm_prompt,
        }

    except Exception as e:
        # 8) ìµœì¢… ì˜ˆì™¸ ë‹¨ì¼í™” ë° ìƒìœ„ ë ˆì´ì–´ ì „ë‹¬ ì—­í• 
        raise ValueError(f"GPT ìƒì„± ì‹¤íŒ¨: {e}")

def extract_last_strategy_proposal(conversation_history: list) -> Optional[str]:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ë§ˆì§€ë§‰ ì „ëµ ì œì•ˆ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    (ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤€ 5ê°€ì§€ ì „ëµ - ìŠ¹ì¸ ì „)
    
    Args:
        conversation_history: [{"role": "user"|"assistant", "content": str}, ...]
    
    Returns:
        ì „ëµ ì œì•ˆ í…ìŠ¤íŠ¸ (5ê°€ì§€ í•­ëª© í¬í•¨) ë˜ëŠ” None
    """
    if not conversation_history:
        return None
    
    # ì—­ìˆœìœ¼ë¡œ íƒìƒ‰ (ìµœê·¼ ë©”ì‹œì§€ë¶€í„°)
    for msg in reversed(conversation_history):
        if msg.get("role") == "assistant":
            content = msg.get("content", "")
            
            # 5ê°€ì§€ ì „ëµ í‚¤ì›Œë“œ í™•ì¸
            if "ë©”ì¸ ë©”ì‹œì§€" in content and "íƒ€ê²Ÿ ê³ ê°" in content:
                # ì „ëµ ì œì•ˆ ë¶€ë¶„ë§Œ ì¶”ì¶œ (1. ~ 5. í¬í•¨)
                match = re.search(
                    r'(1\.\s*\*\*ë©”ì¸ ë©”ì‹œì§€\*\*.*?5\.\s*\*\*ì£¼ìš” ìš”ì†Œ\*\*.*?)(?=\n\n|$)',
                    content,
                    re.DOTALL
                )
                if match:
                    return match.group(1).strip()
                else:
                    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì „ì²´ content ë°˜í™˜ (fallback)
                    return content
    
    return None


async def generate_detailed_image_prompt_with_vision(
    strategy_proposal: str,
    product_image_base64: str,
    business_info: dict
) -> str:
    """
    GPT-4o Visionì„ ì‚¬ìš©í•˜ì—¬ ì œí’ˆ ì´ë¯¸ì§€ ë¶„ì„ + ì „ëµ ê¸°ë°˜ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        strategy_proposal: 5ê°€ì§€ ì „ëµ ì œì•ˆ í…ìŠ¤íŠ¸
        product_image_base64: ì œí’ˆ ì´ë¯¸ì§€ (base64 ì¸ì½”ë”©)
        business_info: ì‚¬ì—…ì ì •ë³´ (ì—…ì¢…, ìœ„ì¹˜ ë“±)
    
    Returns:
        Stable Diffusionìš© ìƒì„¸ ì˜ì–´ í”„ë¡¬í”„íŠ¸
    """
    print("-------strategy_proposal:----------\n", strategy_proposal)
    try:
        # Vision API í˜¸ì¶œìš© í”„ë¡¬í”„íŠ¸ (ë‹¨ìˆœí™” ë²„ì „)
        vision_prompt = f"""
You are a professional product photography director specializing in commercial advertising.

=== Important Context ===
The product in the image you see will be EXTRACTED and COMPOSITED onto a new background scene.
Your task is to create a Stable Diffusion prompt that describes the BACKGROUND SCENE where this product will be placed.

=== Business Information ===
Business Type: {business_info.get('business_type', 'unknown')}

=== Approved Marketing Strategy ===
{strategy_proposal}

=== Task ===
1. Analyze the product image (color, texture, shape, details)
2. Based on the strategy's "Visual Concept" and "Image Style", design a background scene
3. Create a detailed Stable Diffusion prompt in the following structure

=== Required Prompt Structure (ALL IN ENGLISH) ===

**Part 1: Environment & Atmosphere**
- Setting that matches the strategy's visual concept
- Lighting (warm, soft, dramatic, natural, golden hour)
- Overall mood and atmosphere

**Part 2: Background Elements**
- People, objects, decorations matching target audience
- Specify "in the background, slightly out of focus" or "blurred background"

**Part 3: Photography Style**
- "cinematic photography", "commercial photography", "professional product advertising"
- "shallow depth of field", "bokeh effect"

**Part 4: Product Placement**
- Describe the product you see in the image (be specific about what you observe)
- Must include: "in the foreground", "on the table", "sharp and detailed", "product hero shot"

=== Example Output ===
"A cozy winter cafe interior with warm, soft lighting and large windows,
several people sitting and chatting in the background, slightly out of focus,
cinematic photography, shallow depth of field, professional product advertising,
the new seasonal drink on the table in the foreground, sharp and detailed, product hero shot"

=== Critical Rules ===
- ONLY write the prompt in English (NO Korean, NO explanations)
- Background description comes FIRST
- Product description comes LAST (foreground)
- Background must be "out of focus" or "blurred"
- Product must be "sharp", "detailed", "foreground"
-Do not exceed 77 tokens

Now analyze the product image and generate the prompt:
        """.strip()
        
        # GPT-4o Vision API í˜¸ì¶œ
        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": vision_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{product_image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500,
            temperature=0.7
        )
        
        enhanced_prompt = response.choices[0].message.content.strip()
        
        # === ì‹¤íŒ¨ íŒì • ë¡œì§ ===
        
        # 1. ê±°ë¶€ ë©”ì‹œì§€ ê°ì§€
        rejection_words = ["sorry", "can't", "cannot", "unable"]
        if any(word in enhanced_prompt.lower() for word in rejection_words):
            print(f"âš ï¸  Vision API ê±°ë¶€ ê°ì§€: {enhanced_prompt[:100]}")
            raise ValueError("Vision API content policy rejection")
        
        # 2. ë„ˆë¬´ ì§§ì€ ì‘ë‹µ (15ë‹¨ì–´ ë¯¸ë§Œ)
        word_count = len(enhanced_prompt.split())
        if word_count < 15:
            print(f"âš ï¸  ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ: {word_count}ë‹¨ì–´")
            raise ValueError(f"Vision API response too short: {word_count} words")
        
        # === ì„±ê³µ: í† í° ê²€ì¦ ë° ë°˜í™˜ ===
        
        estimated_tokens = int(word_count * 1.3)  # ë³´ìˆ˜ì  ì¶”ì •
        
        if estimated_tokens > 77:
            print(f"âš ï¸  í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({estimated_tokens} í† í° ì¶”ì •), ì˜ë¼ëƒ„")
            # ë‹¨ì–´ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸° (77í† í° â‰ˆ 60ë‹¨ì–´)
            words = enhanced_prompt.split()[:60]
            enhanced_prompt = " ".join(words)
        
        print(f"âœ… Vision ë¶„ì„ ì™„ë£Œ ({estimated_tokens} í† í° ì¶”ì •): {enhanced_prompt}")
        
        return enhanced_prompt
        
    except Exception as e:
        print(f"âŒ Vision API ì‹¤íŒ¨: {e}")
        # Fallback: strategy_proposal ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        print("ğŸ”„ Fallback: strategy_proposalë¡œ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œë„...")
        
        try:
            fallback_prompt = f"""
Create a Stable Diffusion prompt for product advertising based on this marketing strategy.

Business Type: {business_info.get('business_type', 'unknown')}

Marketing Strategy:
{strategy_proposal}

Generate a detailed prompt following this format:
"[environment with lighting], [background elements, blurred], cinematic photography, shallow depth of field, product in foreground, sharp and detailed"

Requirements:
- Write in English only
- Maximum 77 tokens
- Include background scene description
- Specify "blurred background" or "out of focus"
- End with "product in foreground, sharp and detailed"

Your prompt:
            """.strip()
            
            fallback_response = await client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": fallback_prompt}],
                max_tokens=300,
                temperature=0.7
            )
            
            fallback_enhanced = fallback_response.choices[0].message.content.strip()
            
            # Fallbackë„ ë™ì¼í•œ ê²€ì¦ ì ìš©
            rejection_words = ["sorry", "can't", "cannot", "unable"]
            if any(word in fallback_enhanced.lower() for word in rejection_words):
                print(f"âš ï¸  Fallbackë„ ê±°ë¶€ë¨: {fallback_enhanced[:100]}")
                raise ValueError("Fallback also rejected")
            
            word_count = len(fallback_enhanced.split())
            if word_count < 15:
                print(f"âš ï¸  Fallback ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ: {word_count}ë‹¨ì–´")
                raise ValueError(f"Fallback response too short: {word_count} words")
            
            # 77í† í° ì œí•œ ê²€ì¦
            estimated_tokens = int(word_count * 1.3)
            if estimated_tokens > 77:
                print(f"âš ï¸  Fallback í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({estimated_tokens} í† í°), ì˜ë¼ëƒ„")
                words = fallback_enhanced.split()[:60]
                fallback_enhanced = " ".join(words)
            
            print(f"âœ… Fallback í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ ({estimated_tokens} í† í°): {fallback_enhanced}")
            return fallback_enhanced
            
        except Exception as fallback_error:
            print(f"âŒ Fallbackë„ ì‹¤íŒ¨: {fallback_error}")
            # ìµœì¢… ê¸°ë³¸ê°’
            default_fallback = f"Professional product photography for {business_info.get('business_type', 'business')}, cinematic lighting, blurred background, sharp product in foreground, high quality commercial style"
            print(f"âš ï¸  ìµœì¢… ê¸°ë³¸ê°’ ì‚¬ìš©: {default_fallback}")
            return default_fallback


async def extract_city_name_english(location: str) -> str:
    """
    [ë¹„ë™ê¸° ë²„ì „] í•œê¸€ ì§€ì—­ëª…ì„ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜
    ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬" -> "Seoul"
        "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬" -> "Busan"
    """
    import re
    
    # ì´ë¯¸ ì˜ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.match(r'^[a-zA-Z\s]+$', location):
        return location.split()[0]  # ì²« ë‹¨ì–´ë§Œ ë°˜í™˜
    
    # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if not location or location.strip() == "":
        return "Seoul"
    
    try:
        prompt = f"""
        ë‹¤ìŒ í•œêµ­ì–´ ì§€ì—­ëª…ì„ ë‚ ì”¨ APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ì–´ ë„ì‹œëª…ìœ¼ë¡œ ë³€í™˜í•´ì¤˜.
        ë„ì‹œëª…ë§Œ ê°„ë‹¨í•˜ê²Œ ë°˜í™˜í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ('ì„œìš¸ ê°•ë‚¨êµ¬' -> 'Seoul' ì²˜ëŸ¼).
        
        ì…ë ¥: {location}
        ì¶œë ¥ í˜•ì‹: ì˜ì–´ ë„ì‹œëª… (ì˜ˆ: Seoul, Busan, Incheon)
        """
        
        res = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼
            max_tokens=20     # ì§§ì€ ì‘ë‹µë§Œ í•„ìš”
        )
        
        city_name = res.choices[0].message.content.strip()
        
        # ê²°ê³¼ ê²€ì¦ (ì˜ì–´ë§Œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        if re.match(r'^[a-zA-Z\s-]+$', city_name):
            # ì—¬ëŸ¬ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ (ì˜ˆ: "Seoul City" -> "Seoul")
            return city_name.split()[0]
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì´ë©´ ê¸°ë³¸ê°’
            return "Seoul"
            
    except Exception as e:
        print(f"[ì§€ì—­ëª… ë³€í™˜ ì˜¤ë¥˜]: {e}")
        return "Seoul"  # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
